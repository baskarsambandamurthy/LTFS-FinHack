{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e97164a7191d9d43ba8158c0f7e13aa455a0ce9"
   },
   "source": [
    "# Combining your model with a model without outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "7dd3ea3236069cf9706e377d6594c39b5e5a5507"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import gc\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_recall_curve,roc_curve, recall_score,precision_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns  = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "bdcf0af91a3d16d66935cfc55b46b6b1e010f812"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import tpe\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "bf5555c1ad80d3fffe74a6493995959a93b80b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e7bd6dbc0148c27473ca5bff20b4795bf1880546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 s, sys: 272 ms, total: 2.69 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Path = '../input/elo-preproc-3/'\n",
    "Path = '../input/ltfs-fin-model/'\n",
    "\n",
    "train_df = pd.read_csv(Path+'train_preproc.csv',index_col=0)\n",
    "# test_df = pd.read_csv(Path +'test_preproc.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18d93d315eee398fb1cff4ad8d115c21d359cd49"
   },
   "source": [
    "## filtering out outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "3eb5ac784a25271b3433f6371d7b46cdabb420b5"
   },
   "outputs": [],
   "source": [
    "targetcol = 'loan_default'\n",
    "target = train_df[targetcol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "204231995912b388ad8d6bed1c602c6fa29ebb4a"
   },
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d17e1c0e134cb530cb60cc0c11cd61bcbb07f41e"
   },
   "outputs": [],
   "source": [
    "enc_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5b956835abeb534b5d3404ed65dcb49c38bd6542"
   },
   "outputs": [],
   "source": [
    "# def getenc(mask_without_outlier=None):\n",
    "#     tr_encs = []\n",
    "#     val_encs = []\n",
    "#     test_encs = []\n",
    "#     Path='../input/elo-output/'\n",
    "# #     Path='../input/elo-target-encoding-100-splits/'\n",
    "\n",
    "#     for i in range(0,enc_splits):\n",
    "#         cur_tr_enc = pd.read_hdf(Path+'train_targetenc_feats'+str(i)+'.hdf')\n",
    "#         cur_val_enc = pd.read_hdf(Path+'val_targetenc_feats'+str(i)+'.hdf')\n",
    "\n",
    "#         if mask_without_outlier is not None:\n",
    "#             cur_tr_enc = cur_tr_enc[mask_without_outlier]\n",
    "#             cur_val_enc = cur_val_enc[mask_without_outlier]\n",
    "\n",
    "#         tr_encs += [cur_tr_enc]\n",
    "#         val_encs +=[ cur_val_enc]\n",
    "\n",
    "#         test_encs += [pd.read_hdf(Path+'test_targetenc_feats'+str(i)+'.hdf')]\n",
    "#         print('read complete for:',i)\n",
    "        \n",
    "#     return tr_encs,val_encs,test_encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "898eb60e7399b93e4736f360258325e0606156b1"
   },
   "outputs": [],
   "source": [
    "# def lgb_fit(regression,param,tr,y_tr,val,y_val,cur_feval):\n",
    "#     if regression:\n",
    "#         model = lgb.LGBMRegressor(**param)\n",
    "#     else:\n",
    "#         model = lgb.LGBMClassifier(**param)\n",
    "        \n",
    "#     model.fit(tr,y_tr,eval_set=[(val, y_val)],\n",
    "#                     early_stopping_rounds=200,\n",
    "#                     verbose=1000,\n",
    "#                     eval_metric=cur_feval,\n",
    "#              )\n",
    "#     return model\n",
    "# def lgb_predict(model,n_estimators,test):\n",
    "#     preds= model.predict(test,num_iteration = getbestiteration(model,n_estimators))\n",
    "#     return preds\n",
    "# # def xgb_fit(regression,param,tr,y_tr,val,y_val,cur_feval):\n",
    "# #     num_round= param['n_estimators']\n",
    "# #     trn_data = xgb.DMatrix(data=tr, label=y_tr)\n",
    "# #     val_data = xgb.DMatrix(data=val, label=y_val)\n",
    "# #     watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "\n",
    "# #     model = xgb.train(param, trn_data, num_round, watchlist, \n",
    "# #                       early_stopping_rounds=200, verbose_eval=100)\n",
    "\n",
    "# #     return model\n",
    "\n",
    "# def xgb_fit(regression,param,tr,y_tr,val,y_val,cur_feval):\n",
    "#     if regression:\n",
    "#         model = xgb.XGBRegressor(**param)\n",
    " \n",
    "#     else:\n",
    "#         model = xgb.XGBClassifier(**param)\n",
    "\n",
    "#     model.fit(tr,y_tr,eval_set=[(val, y_val)],\n",
    "#                     early_stopping_rounds=200,\n",
    "#                     verbose=50,\n",
    "#                     eval_metric=cur_feval,\n",
    "#              )\n",
    "#     return model\n",
    "# def xgb_predict(model,n_estimators,test):\n",
    "#     preds= model.predict(test)\n",
    "# #     preds = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "#     return preds\n",
    "# def getbestiteration(model,n_estimators):\n",
    "#     if hasattr(model, 'best_iteration'):\n",
    "#         if model.best_iteration is None:\n",
    "#             return n_estimators\n",
    "#         else:\n",
    "#             return model.best_iteration\n",
    "#     elif hasattr(model, 'best_iteration_'):\n",
    "#         if model.best_iteration_ is None:\n",
    "#             return n_estimators\n",
    "#         else:\n",
    "#             return model.best_iteration_\n",
    "    \n",
    "#     return -1\n",
    "\n",
    "# def xgb_getbestscore(model,cur_feval):\n",
    "#     if isinstance(model,xgb.XGBRegressor) :\n",
    "# #         print('model best_score object:',model.get_booster().best_score)\n",
    "#         score= model.get_booster().best_score\n",
    "#     elif isinstance(model,xgb.XGBClassifier):\n",
    "#         print('model best_score object:',model.get_booster().best_score)\n",
    "#         score= model.get_booster().best_score\n",
    "       \n",
    "#     return score\n",
    "\n",
    "# def lgb_getbestscore(model,cur_feval):\n",
    "#     if  isinstance(model,lgb.LGBMRegressor) :\n",
    "#         score= model.best_score_['valid_0'][param['metric']]\n",
    "#     else: #isinstance(model,lgb.LGBMClassifier) :\n",
    "#         if (cur_feval is None):\n",
    "#             score= model.best_score_['valid_0'][param['metric']]\n",
    "#         else:\n",
    "#             score= model.best_score_['valid_0']['f1_score']\n",
    "#     return score\n",
    "# # def xgb_getbestscore(model,cur_feval):\n",
    "# #     return model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "da777d8641e67e90d9064bcdd9e1e8bf5ca5b7c3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def runlgb(train,target,param,cur_features,fold_to_start=None, fold_to_stop=None):\n",
    "\n",
    "   \n",
    "    oof = np.zeros(len(train))\n",
    "#     predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    valid_scores =[]; iterations=[]\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4590)\n",
    "    indices = folds.split(train.values, target.values)\n",
    "        \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(indices):\n",
    "        if (fold_to_stop is not None):\n",
    "            if (fold_ >=fold_to_stop):\n",
    "                break\n",
    "                \n",
    "        if (fold_to_start is not None):\n",
    "            if (fold_ < fold_to_start):\n",
    "                continue\n",
    "                \n",
    "        print()\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "\n",
    "        tr = train.iloc[trn_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "        y_val = target.iloc[val_idx]\n",
    "        y_tr = target.iloc[trn_idx]\n",
    "        \n",
    "        trn_data = lgb.Dataset(tr[cur_features], label=y_tr)#,, categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(val[cur_features], label=y_val)#,, categorical_feature=categorical_feats)\n",
    "        \n",
    "        num_round = param['n_estimators']\n",
    "        print('param:',param)\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=1000, \n",
    "                        early_stopping_rounds = 300)\n",
    "\n",
    "        oof[val_idx] = clf.predict(val[cur_features], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df[\"feature\"] = cur_features\n",
    "        if fold_==0:\n",
    "            fold_importance_df[\"importance\"] =0\n",
    "        fold_importance_df[\"importance\"] += clf.feature_importance() / n_splits\n",
    "        valid_scores+=[clf.best_score['valid_0'][param['metric']]]\n",
    "        iterations +=[clf.best_iteration]\n",
    "#         predictions += clf.predict(test[cur_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print('valid scores:',valid_scores)\n",
    "    cv_score = roc_auc_score(target, oof)\n",
    "    print(\"CV score: {:<8.5f}\".format(cv_score))\n",
    "\n",
    "    return fold_importance_df,oof,cv_score,valid_scores,iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4edddeda48af1a92e187335a2acdc4bb6408e029"
   },
   "outputs": [],
   "source": [
    "# # tr_encs, val_encs,test_encs = getenc(mask_without_outlier=mask_without_outlier)\n",
    "# tr_encs, val_encs,test_encs = getenc()\n",
    "# print(tr_encs[0].shape)\n",
    "# print(val_encs[0].shape)\n",
    "# print(test_encs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d6fed31c5d3cb37a5709bd44013ea22ef7e1955f"
   },
   "outputs": [],
   "source": [
    "# sel_enc_cols =['trans_merged_targetenc_merchant_id_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aadhar_flag', 'Current_pincode_ID', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'Driving_flag', 'Employee_code_ID', 'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES', 'PAN_flag', 'PERFORM_CNS.SCORE', 'PRI.ACTIVE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.DISBURSED.AMOUNT', 'PRI.NO.OF.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.SANCTIONED.AMOUNT', 'PRIMARY.INSTAL.AMT', 'Passport_flag', 'SEC.ACTIVE.ACCTS', 'SEC.CURRENT.BALANCE', 'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT', 'SEC.NO.OF.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.SANCTIONED.AMOUNT', 'State_ID', 'VoterID_flag', 'asset_cost', 'branch_id', 'disbursed_amount', 'ltv', 'manufacturer_id', 'supplier_id', 'age', 'disbursal_month', 'PERFORM_CNS.SCORE.CATEGORY', 'Employment.Type.Category', 'AVERAGE.ACCT.AGE_MONTHS', 'CREDIT.HISTORY.LENGTH_MONTHS']\n"
     ]
    }
   ],
   "source": [
    "exclude_cols =['Date.of.Birth','Employment.Type','DisbursalDate',\n",
    "               'PERFORM_CNS.SCORE.DESCRIPTION','AVERAGE.ACCT.AGE','CREDIT.HISTORY.LENGTH',\n",
    "               'MobileNo_Avl_Flag','disbursal_year','disbursal_day','disbursal_dayofweek',\n",
    "               'date_of_birth', 'disbursal_date',\n",
    "               'UniqueID',targetcol]\n",
    "features = [c for c in train_df.columns if c not in exclude_cols]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "0a6ff52d1cf6a60312f7a1748624e3b9e6814611"
   },
   "outputs": [],
   "source": [
    "n_splits =5\n",
    "fold_to_start = 0\n",
    "fold_to_stop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "50822221ec285caddcb75fe73d1e075e7496f474"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def computescore(hyperparameters,train,features,target):\n",
    "    \n",
    "    hyperparameters['learning_rate'] = 0.01\n",
    "    hyperparameters['boosting'] = 'gbdt'\n",
    "    hyperparameters['bagging_seed'] = 2018\n",
    "    hyperparameters['bagging_freq'] = 2\n",
    "    hyperparameters['min_data_in_bin'] = 100\n",
    "    hyperparameters['n_estimators'] = 10000\n",
    "    hyperparameters['objective'] = \"binary\"\n",
    "    hyperparameters['metric'] = \"auc\"\n",
    "    hyperparameters['random_state'] = 2333\n",
    "    hyperparameters['max_depth'] = 15\n",
    "    hyperparameters['scale_pos_weight'] = 1  \n",
    "    \n",
    "    fold_importance_df,oof,cv_score,valid_scores,iterations\\\n",
    "        = runlgb(train,target,hyperparameters,features,\n",
    "                 fold_to_start=fold_to_start,fold_to_stop=fold_to_stop)\n",
    "    \n",
    "\n",
    "    return cv_score, valid_scores, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'colsample_bytree': 0.7196484570790651,\n",
    "   'min_child_samples': 235,\n",
    "   'num_leaves': 36,\n",
    "   'reg_alpha': 0.6474702076362333,\n",
    "   'reg_lambda': 0.021458900986429996,\n",
    "   'subsample': 0.8873887256306612,\n",
    "   'subsample_for_bin': 110000,\n",
    "   'learning_rate': 0.01,\n",
    "   'boosting': 'gbdt',\n",
    "   'bagging_seed': 2018,\n",
    "   'bagging_freq': 2,\n",
    "   'min_data_in_bin': 100,\n",
    "   'n_estimators': 10000,\n",
    "   'objective': 'binary',\n",
    "   'metric': 'auc',\n",
    "   'random_state': 2333,\n",
    "   'max_depth': 15,\n",
    "   'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# def runlgb_normal(ispermutefeats,train,test,param,cur_features,score_function=None):\n",
    "\n",
    "#     overall_sel_feats =[]\n",
    "#     overall_imp_df = pd.DataFrame()\n",
    "#     overall_imp_df['feature']= np.array(cur_features)\n",
    "#     overall_imp_df['overall_score_mean'] =0 \n",
    "#     overall_imp_df['overall_score_max'] =-9999 \n",
    "#     overall_imp_df['overall_score_min'] =9999 \n",
    "    \n",
    "#     oof = np.zeros(len(train))\n",
    "#     predictions = np.zeros(len(test))\n",
    "#     start = time.time()\n",
    "#     valid_scores =[]\n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "#     folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4590)\n",
    "#     indices = folds.split(train.values, target.values)\n",
    "        \n",
    "#     for fold_, (trn_idx, val_idx) in enumerate(indices):\n",
    "#         print()\n",
    "#         print(\"fold n°{}\".format(fold_))\n",
    "\n",
    "#         tr = train.iloc[trn_idx]\n",
    "#         val = train.iloc[val_idx]\n",
    "#         y_val = target.iloc[val_idx]\n",
    "#         y_tr = target.iloc[trn_idx]\n",
    "        \n",
    "# #         val_index_ser = pd.Series(np.array(val.index))\n",
    "# #         print('val shape:',val.shape)\n",
    "# #         print('val index head:',val_index_ser.head(20))\n",
    "# #         print('val index tail:',val_index_ser.tail(20))\n",
    "        \n",
    "#         trn_data = lgb.Dataset(tr[cur_features], label=y_tr)#,, categorical_feature=categorical_feats)\n",
    "#         val_data = lgb.Dataset(val[cur_features], label=y_val)#,, categorical_feature=categorical_feats)\n",
    "        \n",
    "#         clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=500, \n",
    "#                         early_stopping_rounds = 300)\n",
    "\n",
    "#         #Prediction based on current fold selected features\n",
    "#         if ispermutefeats:\n",
    "            \n",
    "#             selected_features, importance_df = permutation_feature_selection(clf, val[cur_features], \n",
    "#                                                                              y_val,score_function,\n",
    "#                                                                              rep=4,max_delta_score=max_delta_score)\n",
    "#             overall_sel_feats += [selected_features]\n",
    "#             print(selected_features)\n",
    "\n",
    "# #             print('overal imp shape:{0} importance_df shape:{1}'.format(overall_imp_df.shape,importance_df.shape))\n",
    "            \n",
    "#             overall_imp_df['fold_'+str(fold_)+'score_mean'] = importance_df['delta_score_mean']\n",
    "#             overall_imp_df['fold_'+str(fold_)+'score_max'] = importance_df['delta_score_max']\n",
    "#             overall_imp_df['fold_'+str(fold_)+'score_min'] = importance_df['delta_score_min']\n",
    "#         else:\n",
    "#             oof[val_idx] = clf.predict(val[cur_features], num_iteration=clf.best_iteration)\n",
    "\n",
    "#             fold_importance_df[\"feature\"] = cur_features\n",
    "#             if fold_==0:\n",
    "#                 fold_importance_df[\"importance\"] =0\n",
    "#             fold_importance_df[\"importance\"] += clf.feature_importance() / n_splits\n",
    "#             valid_scores+=[clf.best_score['valid_0'][param['metric']]]\n",
    "#             predictions += clf.predict(test[cur_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "#     if ispermutefeats:\n",
    "#         fold_mean_cols = [col for col in overall_imp_df.columns if ('score_mean' in col) and ('fold_' in col) ]\n",
    "#         fold_max_cols = [col for col in overall_imp_df.columns if ('score_max' in col) and ('fold_' in col) ]\n",
    "#         fold_min_cols = [col for col in overall_imp_df.columns if ('score_min' in col) and ('fold_' in col) ]\n",
    "#         overall_imp_df['overall_score_mean'] = overall_imp_df[fold_mean_cols].mean(axis=1)\n",
    "#         overall_imp_df['overall_score_max'] = overall_imp_df[fold_max_cols].max(axis=1)\n",
    "#         overall_imp_df['overall_score_min'] = overall_imp_df[fold_min_cols].min(axis=1)\n",
    "#     else:\n",
    "#         print('valid scores:',valid_scores)\n",
    "#         print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "\n",
    "#     return fold_importance_df,predictions,oof,overall_imp_df,overall_sel_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_round = param['n_estimators']\n",
    "# fold_importance_df,predictions_2,oof_2,overall_imp_df,overall_sel_feats = \\\n",
    "#         runlgb_normal(False,train_df,test_df,param,features,score_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2813cba674b6561cadca2e04850a3e28ac8ff1f2"
   },
   "outputs": [],
   "source": [
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    print('ITERATION:',ITERATION)\n",
    "    \n",
    "    print('hyper params')\n",
    "    print('subsample: {0} num_leaves: {1} subsample_for_bin: {2}'.format(\\\n",
    "            hyperparameters['subsample'],hyperparameters['num_leaves'],hyperparameters['subsample_for_bin']))\n",
    "    print('min_child_samples: {0} reg_alpha: {1} reg_lambda: {2} colsample_bytree: {3}'.format(\\\n",
    "            hyperparameters['min_child_samples'],hyperparameters['reg_alpha'],\n",
    "            hyperparameters['reg_lambda'],hyperparameters['colsample_bytree']))\n",
    "    \n",
    "#     # Using early stopping to find number of trees trained\n",
    "#     if 'n_estimators' in hyperparameters:\n",
    "#         del hyperparameters['n_estimators']\n",
    "    \n",
    "#     # Retrieve the subsample\n",
    "#     subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "#     # Extract the boosting type and subsample to top level keys\n",
    "#     hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "#     hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    best_score,val_scores,n_estimators = computescore(hyperparameters,train_df,\n",
    "                                                      features,target)\n",
    "    \n",
    "#     cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "#                         early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "#     Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score,val_scores])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "97efafa3e07009e048bd51a417b8926f2a510d0e"
   },
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "#     'boosting_type': hp.choice('boosting_type', \n",
    "#                                             [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "#                                              {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "#                                              {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 80, 1),\n",
    "#     'bagging_freq' : hp.quniform('bagging_freq', 2, 25, 1),\n",
    "#     'learning_rate': hp.loguniform('learning_rate', np.log(0.02), np.log(0.1)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 80000, 160000, 10000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples',30, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "#     'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "0035eace7d9f60cac9bd97865502acd6b659efd8"
   },
   "outputs": [],
   "source": [
    "tpe_algorithm = tpe.suggest\n",
    "# Record results\n",
    "trials = Trials()\n",
    "# import json\n",
    "# import pickle\n",
    "\n",
    "Path = \"../input/ltfs-fin-bayesian/\"\n",
    "\n",
    "# # with open(Path+'trials.json', 'r') as f:\n",
    "trials = pickle.load(open(Path+\"trials_cls.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "bf5673cea0d3b8c31d794d3b01164e7a989c529b"
   },
   "outputs": [],
   "source": [
    "# Create a file and open a connection\n",
    "OUT_FILE = 'bayes_elo_cls.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score','valid_scores']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "eab26f1fbb832d7381f51d2501240fd9700a8879"
   },
   "outputs": [],
   "source": [
    "param ={'metric':'auc'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "c8248838ca6527cd02a2bd3523803cc6c8bc9202",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION:\n",
      "1\n",
      "hyper params\n",
      "subsample: 0.988456640881867 num_leaves: 64.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 115.0 reg_alpha: 0.46711636846944976 reg_lambda: 0.8012130503992826 colsample_bytree: 0.6450913216384198\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6450913216384198, 'min_child_samples': 115, 'num_leaves': 64, 'reg_alpha': 0.46711636846944976, 'reg_lambda': 0.8012130503992826, 'subsample': 0.988456640881867, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674277\n",
      "[2000]\tvalid_0's auc: 0.675868\n",
      "[3000]\tvalid_0's auc: 0.676083\n",
      "Early stopping, best iteration is:\n",
      "[2765]\tvalid_0's auc: 0.676229\n",
      "valid scores:\n",
      "[0.6762289505087588]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "2\n",
      "hyper params\n",
      "subsample: 0.9694401211538677 num_leaves: 76.0 subsample_for_bin: 110000.0\n",
      "min_child_samples: 45.0 reg_alpha: 0.28807085806697474 reg_lambda: 0.8368969422238387 colsample_bytree: 0.6277635388357228\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6277635388357228, 'min_child_samples': 45, 'num_leaves': 76, 'reg_alpha': 0.28807085806697474, 'reg_lambda': 0.8368969422238387, 'subsample': 0.9694401211538677, 'subsample_for_bin': 110000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  1%|          | 1/100 [01:53<3:05:25, 112.38s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674336\n",
      "[2000]\tvalid_0's auc: 0.676063\n",
      "Early stopping, best iteration is:\n",
      "[2443]\tvalid_0's auc: 0.676212\n",
      "valid scores:\n",
      "[0.6762123357300509]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "3\n",
      "hyper params\n",
      "subsample: 0.9476250469715116 num_leaves: 23.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 100.0 reg_alpha: 0.5450666256007439 reg_lambda: 0.9502078300837423 colsample_bytree: 0.847677012224715\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.847677012224715, 'min_child_samples': 100, 'num_leaves': 23, 'reg_alpha': 0.5450666256007439, 'reg_lambda': 0.9502078300837423, 'subsample': 0.9476250469715116, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  2%|▏         | 2/100 [03:33<2:57:36, 108.74s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67002\n",
      "[2000]\tvalid_0's auc: 0.673093\n",
      "[3000]\tvalid_0's auc: 0.674445\n",
      "[4000]\tvalid_0's auc: 0.674836\n",
      "[5000]\tvalid_0's auc: 0.675096\n",
      "Early stopping, best iteration is:\n",
      "[4734]\tvalid_0's auc: 0.675253\n",
      "valid scores:\n",
      "[0.6752529482695503]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "4\n",
      "hyper params\n",
      "subsample: 0.8609525865436752 num_leaves: 73.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 240.0 reg_alpha: 0.5001901469385549 reg_lambda: 0.9002851325465323 colsample_bytree: 0.735555969850078\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.735555969850078, 'min_child_samples': 240, 'num_leaves': 73, 'reg_alpha': 0.5001901469385549, 'reg_lambda': 0.9002851325465323, 'subsample': 0.8609525865436752, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  3%|▎         | 3/100 [05:48<3:08:45, 116.76s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67502\n",
      "Early stopping, best iteration is:\n",
      "[1667]\tvalid_0's auc: 0.676184\n",
      "valid scores:\n",
      "[0.6761843567186955]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "5\n",
      "hyper params\n",
      "subsample: 0.7457864332910822 num_leaves: 68.0 subsample_for_bin: 120000.0\n",
      "min_child_samples: 140.0 reg_alpha: 0.2635858627228491 reg_lambda: 0.8768874887567868 colsample_bytree: 0.690788832211296\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.690788832211296, 'min_child_samples': 140, 'num_leaves': 68, 'reg_alpha': 0.2635858627228491, 'reg_lambda': 0.8768874887567868, 'subsample': 0.7457864332910822, 'subsample_for_bin': 120000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  4%|▍         | 4/100 [07:11<2:50:39, 106.66s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674635\n",
      "Early stopping, best iteration is:\n",
      "[1462]\tvalid_0's auc: 0.675515\n",
      "valid scores:\n",
      "[0.6755150818830707]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "6\n",
      "hyper params\n",
      "subsample: 0.9386214470369495 num_leaves: 55.0 subsample_for_bin: 80000.0\n",
      "min_child_samples: 125.0 reg_alpha: 0.13699337174354193 reg_lambda: 0.926137252081774 colsample_bytree: 0.7227302257633448\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7227302257633448, 'min_child_samples': 125, 'num_leaves': 55, 'reg_alpha': 0.13699337174354193, 'reg_lambda': 0.926137252081774, 'subsample': 0.9386214470369495, 'subsample_for_bin': 80000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  5%|▌         | 5/100 [08:19<2:30:29, 95.05s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673736\n",
      "[2000]\tvalid_0's auc: 0.675748\n",
      "Early stopping, best iteration is:\n",
      "[2584]\tvalid_0's auc: 0.676065\n",
      "valid scores:\n",
      "[0.6760652325028516]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "7\n",
      "hyper params\n",
      "subsample: 0.8933522848202344 num_leaves: 72.0 subsample_for_bin: 130000.0\n",
      "min_child_samples: 75.0 reg_alpha: 0.31846482139395116 reg_lambda: 0.9808804821446014 colsample_bytree: 0.6607464696730139\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6607464696730139, 'min_child_samples': 75, 'num_leaves': 72, 'reg_alpha': 0.31846482139395116, 'reg_lambda': 0.9808804821446014, 'subsample': 0.8933522848202344, 'subsample_for_bin': 130000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  6%|▌         | 6/100 [10:00<2:31:40, 96.81s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674702\n",
      "Early stopping, best iteration is:\n",
      "[1687]\tvalid_0's auc: 0.676125\n",
      "valid scores:\n",
      "[0.6761251111858259]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "8\n",
      "hyper params\n",
      "subsample: 0.8821727347473813 num_leaves: 65.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 205.0 reg_alpha: 0.7332456026899354 reg_lambda: 0.9999122009085852 colsample_bytree: 0.6003291131541303\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6003291131541303, 'min_child_samples': 205, 'num_leaves': 65, 'reg_alpha': 0.7332456026899354, 'reg_lambda': 0.9999122009085852, 'subsample': 0.8821727347473813, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  7%|▋         | 7/100 [11:18<2:21:00, 90.97s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674668\n",
      "[2000]\tvalid_0's auc: 0.676216\n",
      "Early stopping, best iteration is:\n",
      "[2005]\tvalid_0's auc: 0.676237\n",
      "valid scores:\n",
      "[0.6762374953294018]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "9\n",
      "hyper params\n",
      "subsample: 0.9094675765209614 num_leaves: 70.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 160.0 reg_alpha: 0.3808552222410257 reg_lambda: 0.813438528260921 colsample_bytree: 0.7708429758960753\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7708429758960753, 'min_child_samples': 160, 'num_leaves': 70, 'reg_alpha': 0.3808552222410257, 'reg_lambda': 0.813438528260921, 'subsample': 0.9094675765209614, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  8%|▊         | 8/100 [12:46<2:18:06, 90.07s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674071\n",
      "[2000]\tvalid_0's auc: 0.675609\n",
      "Early stopping, best iteration is:\n",
      "[2130]\tvalid_0's auc: 0.675761\n",
      "valid scores:\n",
      "[0.6757611148141223]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "10\n",
      "hyper params\n",
      "subsample: 0.9522551559060276 num_leaves: 62.0 subsample_for_bin: 130000.0\n",
      "min_child_samples: 80.0 reg_alpha: 0.1821215233547157 reg_lambda: 0.7601913958924875 colsample_bytree: 0.6156703444511352\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6156703444511352, 'min_child_samples': 80, 'num_leaves': 62, 'reg_alpha': 0.1821215233547157, 'reg_lambda': 0.7601913958924875, 'subsample': 0.9522551559060276, 'subsample_for_bin': 130000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      "  9%|▉         | 9/100 [14:23<2:19:57, 92.28s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674315\n",
      "[2000]\tvalid_0's auc: 0.676215\n",
      "Early stopping, best iteration is:\n",
      "[2090]\tvalid_0's auc: 0.676343\n",
      "valid scores:\n",
      "[0.67634347491615]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "11\n",
      "hyper params\n",
      "subsample: 0.9825374275506054 num_leaves: 66.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 30.0 reg_alpha: 0.4134566841068962 reg_lambda: 0.06268019886579079 colsample_bytree: 0.9115052245596644\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.9115052245596644, 'min_child_samples': 30, 'num_leaves': 66, 'reg_alpha': 0.4134566841068962, 'reg_lambda': 0.06268019886579079, 'subsample': 0.9825374275506054, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 10%|█         | 10/100 [15:47<2:14:40, 89.78s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.672397\n",
      "[2000]\tvalid_0's auc: 0.673716\n",
      "Early stopping, best iteration is:\n",
      "[2220]\tvalid_0's auc: 0.67384\n",
      "valid scores:\n",
      "[0.6738403470937532]\n",
      "CV score: 0.50696 \n",
      "ITERATION:\n",
      "12\n",
      "hyper params\n",
      "subsample: 0.9008628637641976 num_leaves: 53.0 subsample_for_bin: 90000.0\n",
      "min_child_samples: 195.0 reg_alpha: 0.48077123825331913 reg_lambda: 0.8513726795066012 colsample_bytree: 0.6375490553445331\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6375490553445331, 'min_child_samples': 195, 'num_leaves': 53, 'reg_alpha': 0.48077123825331913, 'reg_lambda': 0.8513726795066012, 'subsample': 0.9008628637641976, 'subsample_for_bin': 90000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 11%|█         | 11/100 [17:24<2:16:18, 91.89s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674278\n",
      "[2000]\tvalid_0's auc: 0.676187\n",
      "Early stopping, best iteration is:\n",
      "[2329]\tvalid_0's auc: 0.676474\n",
      "valid scores:\n",
      "[0.6764736346136258]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "13\n",
      "hyper params\n",
      "subsample: 0.9955363410727381 num_leaves: 79.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 65.0 reg_alpha: 0.2327970880069945 reg_lambda: 0.7160786568224435 colsample_bytree: 0.6506375892886253\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6506375892886253, 'min_child_samples': 65, 'num_leaves': 79, 'reg_alpha': 0.2327970880069945, 'reg_lambda': 0.7160786568224435, 'subsample': 0.9955363410727381, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 12%|█▏        | 12/100 [18:55<2:14:33, 91.75s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674331\n",
      "[2000]\tvalid_0's auc: 0.675587\n",
      "Early stopping, best iteration is:\n",
      "[1838]\tvalid_0's auc: 0.675694\n",
      "valid scores:\n",
      "[0.6756938777905086]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "14\n",
      "hyper params\n",
      "subsample: 0.6559198814295584 num_leaves: 57.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 55.0 reg_alpha: 0.5251737913606148 reg_lambda: 0.9607846941688244 colsample_bytree: 0.8332943688813832\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.8332943688813832, 'min_child_samples': 55, 'num_leaves': 57, 'reg_alpha': 0.5251737913606148, 'reg_lambda': 0.9607846941688244, 'subsample': 0.6559198814295584, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 13%|█▎        | 13/100 [20:18<2:09:10, 89.08s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673959\n",
      "[2000]\tvalid_0's auc: 0.675207\n",
      "Early stopping, best iteration is:\n",
      "[2148]\tvalid_0's auc: 0.675356\n",
      "valid scores:\n",
      "[0.6753556579336426]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "15\n",
      "hyper params\n",
      "subsample: 0.9998330279701928 num_leaves: 63.0 subsample_for_bin: 110000.0\n",
      "min_child_samples: 175.0 reg_alpha: 0.20487458321020502 reg_lambda: 0.6509948482265863 colsample_bytree: 0.6092848864208668\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6092848864208668, 'min_child_samples': 175, 'num_leaves': 63, 'reg_alpha': 0.20487458321020502, 'reg_lambda': 0.6509948482265863, 'subsample': 0.9998330279701928, 'subsample_for_bin': 110000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 14%|█▍        | 14/100 [21:39<2:04:21, 86.76s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673927\n",
      "[2000]\tvalid_0's auc: 0.675462\n",
      "Early stopping, best iteration is:\n",
      "[1986]\tvalid_0's auc: 0.675503\n",
      "valid scores:\n",
      "[0.6755030872060882]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "16\n",
      "hyper params\n",
      "subsample: 0.9638479394165473 num_leaves: 20.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 145.0 reg_alpha: 0.432936848014101 reg_lambda: 0.8956203563045562 colsample_bytree: 0.7113247279209046\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7113247279209046, 'min_child_samples': 145, 'num_leaves': 20, 'reg_alpha': 0.432936848014101, 'reg_lambda': 0.8956203563045562, 'subsample': 0.9638479394165473, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 15%|█▌        | 15/100 [23:06<2:03:00, 86.82s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.669139\n",
      "[2000]\tvalid_0's auc: 0.67212\n",
      "[3000]\tvalid_0's auc: 0.673728\n",
      "[4000]\tvalid_0's auc: 0.674383\n",
      "[5000]\tvalid_0's auc: 0.674855\n",
      "Early stopping, best iteration is:\n",
      "[5232]\tvalid_0's auc: 0.674923\n",
      "valid scores:\n",
      "[0.6749228105467124]\n",
      "CV score: 0.50700 \n",
      "ITERATION:\n",
      "17\n",
      "hyper params\n",
      "subsample: 0.7604614577463267 num_leaves: 77.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 105.0 reg_alpha: 0.36218079806369263 reg_lambda: 0.7919115028480268 colsample_bytree: 0.6259789272715941\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6259789272715941, 'min_child_samples': 105, 'num_leaves': 77, 'reg_alpha': 0.36218079806369263, 'reg_lambda': 0.7919115028480268, 'subsample': 0.7604614577463267, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 16%|█▌        | 16/100 [25:29<2:25:00, 103.58s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674818\n",
      "Early stopping, best iteration is:\n",
      "[1608]\tvalid_0's auc: 0.675757\n",
      "valid scores:\n",
      "[0.6757571779192407]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "18\n",
      "hyper params\n",
      "subsample: 0.9217139062639172 num_leaves: 75.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 40.0 reg_alpha: 0.6340087029219232 reg_lambda: 0.9321442166325368 colsample_bytree: 0.7015879707523571\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7015879707523571, 'min_child_samples': 40, 'num_leaves': 75, 'reg_alpha': 0.6340087029219232, 'reg_lambda': 0.9321442166325368, 'subsample': 0.9217139062639172, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 17%|█▋        | 17/100 [26:42<2:10:31, 94.36s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67429\n",
      "[2000]\tvalid_0's auc: 0.675962\n",
      "Early stopping, best iteration is:\n",
      "[2185]\tvalid_0's auc: 0.676066\n",
      "valid scores:\n",
      "[0.6760655328432857]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "19\n",
      "hyper params\n",
      "subsample: 0.8659935738852303 num_leaves: 71.0 subsample_for_bin: 90000.0\n",
      "min_child_samples: 260.0 reg_alpha: 0.5888026743623317 reg_lambda: 0.8711257961280156 colsample_bytree: 0.985856265308702\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.985856265308702, 'min_child_samples': 260, 'num_leaves': 71, 'reg_alpha': 0.5888026743623317, 'reg_lambda': 0.8711257961280156, 'subsample': 0.8659935738852303, 'subsample_for_bin': 90000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 18%|█▊        | 18/100 [28:14<2:08:09, 93.77s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673951\n",
      "[2000]\tvalid_0's auc: 0.674902\n",
      "Early stopping, best iteration is:\n",
      "[1849]\tvalid_0's auc: 0.675058\n",
      "valid scores:\n",
      "[0.6750580002700196]\n",
      "CV score: 0.50701 \n",
      "ITERATION:\n",
      "20\n",
      "hyper params\n",
      "subsample: 0.9324394259886841 num_leaves: 74.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 95.0 reg_alpha: 0.2902270280519068 reg_lambda: 0.8364210563143828 colsample_bytree: 0.6779256431015753\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6779256431015753, 'min_child_samples': 95, 'num_leaves': 74, 'reg_alpha': 0.2902270280519068, 'reg_lambda': 0.8364210563143828, 'subsample': 0.9324394259886841, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 19%|█▉        | 19/100 [29:53<2:08:28, 95.17s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674204\n",
      "[2000]\tvalid_0's auc: 0.675669\n",
      "Early stopping, best iteration is:\n",
      "[2014]\tvalid_0's auc: 0.675732\n",
      "valid scores:\n",
      "[0.6757320656708592]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "21\n",
      "hyper params\n",
      "subsample: 0.9735200029660643 num_leaves: 80.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 120.0 reg_alpha: 0.2533231951553674 reg_lambda: 0.9170380503184582 colsample_bytree: 0.7611934642109246\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7611934642109246, 'min_child_samples': 120, 'num_leaves': 80, 'reg_alpha': 0.2533231951553674, 'reg_lambda': 0.9170380503184582, 'subsample': 0.9735200029660643, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 20%|██        | 20/100 [31:22<2:04:40, 93.51s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674824\n",
      "[2000]\tvalid_0's auc: 0.676149\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's auc: 0.676301\n",
      "valid scores:\n",
      "[0.6763012256755128]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "22\n",
      "hyper params\n",
      "subsample: 0.8214519411058787 num_leaves: 68.0 subsample_for_bin: 80000.0\n",
      "min_child_samples: 185.0 reg_alpha: 0.33549683274490016 reg_lambda: 0.6099970477561807 colsample_bytree: 0.6572425525331347\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6572425525331347, 'min_child_samples': 185, 'num_leaves': 68, 'reg_alpha': 0.33549683274490016, 'reg_lambda': 0.6099970477561807, 'subsample': 0.8214519411058787, 'subsample_for_bin': 80000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 21%|██        | 21/100 [32:52<2:01:37, 92.37s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674926\n",
      "[2000]\tvalid_0's auc: 0.675887\n",
      "Early stopping, best iteration is:\n",
      "[1855]\tvalid_0's auc: 0.675939\n",
      "valid scores:\n",
      "[0.6759387945915679]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "23\n",
      "hyper params\n",
      "subsample: 0.9865721362966641 num_leaves: 78.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 130.0 reg_alpha: 0.4683007335005333 reg_lambda: 0.7386150067353587 colsample_bytree: 0.6206432012674803\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6206432012674803, 'min_child_samples': 130, 'num_leaves': 78, 'reg_alpha': 0.4683007335005333, 'reg_lambda': 0.7386150067353587, 'subsample': 0.9865721362966641, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 22%|██▏       | 22/100 [34:13<1:55:40, 88.98s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674667\n",
      "[2000]\tvalid_0's auc: 0.675908\n",
      "Early stopping, best iteration is:\n",
      "[1785]\tvalid_0's auc: 0.675982\n",
      "valid scores:\n",
      "[0.6759820828477615]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "24\n",
      "hyper params\n",
      "subsample: 0.9457827348465191 num_leaves: 61.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 230.0 reg_alpha: 0.3049832855622113 reg_lambda: 0.7795142486326977 colsample_bytree: 0.6432078195260402\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6432078195260402, 'min_child_samples': 230, 'num_leaves': 61, 'reg_alpha': 0.3049832855622113, 'reg_lambda': 0.7795142486326977, 'subsample': 0.9457827348465191, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 23%|██▎       | 23/100 [35:38<1:52:44, 87.85s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674593\n",
      "[2000]\tvalid_0's auc: 0.67662\n",
      "Early stopping, best iteration is:\n",
      "[2240]\tvalid_0's auc: 0.676754\n",
      "valid scores:\n",
      "[0.6767535532512398]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "25\n",
      "hyper params\n",
      "subsample: 0.9610034981370909 num_leaves: 60.0 subsample_for_bin: 110000.0\n",
      "min_child_samples: 80.0 reg_alpha: 0.03058667521739289 reg_lambda: 0.9470491543214119 colsample_bytree: 0.6669717055382366\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6669717055382366, 'min_child_samples': 80, 'num_leaves': 60, 'reg_alpha': 0.03058667521739289, 'reg_lambda': 0.9470491543214119, 'subsample': 0.9610034981370909, 'subsample_for_bin': 110000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 24%|██▍       | 24/100 [37:14<1:54:19, 90.25s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673555\n",
      "[2000]\tvalid_0's auc: 0.675811\n",
      "Early stopping, best iteration is:\n",
      "[2380]\tvalid_0's auc: 0.676139\n",
      "valid scores:\n",
      "[0.6761391852468059]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "26\n",
      "hyper params\n",
      "subsample: 0.6678938080200838 num_leaves: 51.0 subsample_for_bin: 130000.0\n",
      "min_child_samples: 110.0 reg_alpha: 0.5080648993785531 reg_lambda: 0.9973347338865202 colsample_bytree: 0.6338024922051699\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6338024922051699, 'min_child_samples': 110, 'num_leaves': 51, 'reg_alpha': 0.5080648993785531, 'reg_lambda': 0.9973347338865202, 'subsample': 0.6678938080200838, 'subsample_for_bin': 130000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 25%|██▌       | 25/100 [38:48<1:54:08, 91.31s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673447\n",
      "[2000]\tvalid_0's auc: 0.675382\n",
      "Early stopping, best iteration is:\n",
      "[2409]\tvalid_0's auc: 0.675688\n",
      "valid scores:\n",
      "[0.6756882998463174]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "27\n",
      "hyper params\n",
      "subsample: 0.9400291875655707 num_leaves: 47.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 150.0 reg_alpha: 0.41002348636117525 reg_lambda: 0.6861221124684521 colsample_bytree: 0.8830091015456445\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.8830091015456445, 'min_child_samples': 150, 'num_leaves': 47, 'reg_alpha': 0.41002348636117525, 'reg_lambda': 0.6861221124684521, 'subsample': 0.9400291875655707, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 26%|██▌       | 26/100 [40:10<1:49:21, 88.67s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.672868\n",
      "[2000]\tvalid_0's auc: 0.675099\n",
      "Early stopping, best iteration is:\n",
      "[2626]\tvalid_0's auc: 0.675645\n",
      "valid scores:\n",
      "[0.6756454323373088]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "28\n",
      "hyper params\n",
      "subsample: 0.9915388159661432 num_leaves: 70.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 50.0 reg_alpha: 0.38021606693418086 reg_lambda: 0.13309266250148089 colsample_bytree: 0.9273558646719258\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.9273558646719258, 'min_child_samples': 50, 'num_leaves': 70, 'reg_alpha': 0.38021606693418086, 'reg_lambda': 0.13309266250148089, 'subsample': 0.9915388159661432, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 27%|██▋       | 27/100 [41:55<1:53:48, 93.55s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.672436\n",
      "[2000]\tvalid_0's auc: 0.674125\n",
      "Early stopping, best iteration is:\n",
      "[1951]\tvalid_0's auc: 0.674216\n",
      "valid scores:\n",
      "[0.6742160405077748]\n",
      "CV score: 0.50698 \n",
      "ITERATION:\n",
      "29\n",
      "hyper params\n",
      "subsample: 0.9136219232899767 num_leaves: 72.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 90.0 reg_alpha: 0.5584431482099724 reg_lambda: 0.8146310057744794 colsample_bytree: 0.8152948787687401\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.8152948787687401, 'min_child_samples': 90, 'num_leaves': 72, 'reg_alpha': 0.5584431482099724, 'reg_lambda': 0.8146310057744794, 'subsample': 0.9136219232899767, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 28%|██▊       | 28/100 [43:27<1:51:24, 92.84s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674548\n",
      "[2000]\tvalid_0's auc: 0.676116\n",
      "Early stopping, best iteration is:\n",
      "[2025]\tvalid_0's auc: 0.676159\n",
      "valid scores:\n",
      "[0.676159201177999]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "30\n",
      "hyper params\n",
      "subsample: 0.9778555803510699 num_leaves: 66.0 subsample_for_bin: 120000.0\n",
      "min_child_samples: 165.0 reg_alpha: 0.4407278766440953 reg_lambda: 0.8839412656386955 colsample_bytree: 0.607625885953233\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.607625885953233, 'min_child_samples': 165, 'num_leaves': 66, 'reg_alpha': 0.4407278766440953, 'reg_lambda': 0.8839412656386955, 'subsample': 0.9778555803510699, 'subsample_for_bin': 120000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 29%|██▉       | 29/100 [44:59<1:49:31, 92.56s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674175\n",
      "[2000]\tvalid_0's auc: 0.675691\n",
      "Early stopping, best iteration is:\n",
      "[2223]\tvalid_0's auc: 0.675846\n",
      "valid scores:\n",
      "[0.6758463600878278]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "31\n",
      "hyper params\n",
      "subsample: 0.874486966506823 num_leaves: 64.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 135.0 reg_alpha: 0.22370591351001323 reg_lambda: 0.8605246013674355 colsample_bytree: 0.6849459289202497\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6849459289202497, 'min_child_samples': 135, 'num_leaves': 64, 'reg_alpha': 0.22370591351001323, 'reg_lambda': 0.8605246013674355, 'subsample': 0.874486966506823, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 30%|███       | 30/100 [46:34<1:48:52, 93.32s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674391\n",
      "[2000]\tvalid_0's auc: 0.676195\n",
      "Early stopping, best iteration is:\n",
      "[2237]\tvalid_0's auc: 0.676333\n",
      "valid scores:\n",
      "[0.6763330008817264]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "32\n",
      "hyper params\n",
      "subsample: 0.9276690220104051 num_leaves: 76.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 245.0 reg_alpha: 0.7965014622581202 reg_lambda: 0.7700586081321938 colsample_bytree: 0.7973655264408361\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7973655264408361, 'min_child_samples': 245, 'num_leaves': 76, 'reg_alpha': 0.7965014622581202, 'reg_lambda': 0.7700586081321938, 'subsample': 0.9276690220104051, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 31%|███       | 31/100 [48:06<1:47:01, 93.07s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674758\n",
      "[2000]\tvalid_0's auc: 0.676137\n",
      "Early stopping, best iteration is:\n",
      "[1940]\tvalid_0's auc: 0.676211\n",
      "valid scores:\n",
      "[0.6762109003192367]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "33\n",
      "hyper params\n",
      "subsample: 0.6162700131718355 num_leaves: 56.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 65.0 reg_alpha: 0.6476342328905603 reg_lambda: 0.9718600854662549 colsample_bytree: 0.6920401171246812\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6920401171246812, 'min_child_samples': 65, 'num_leaves': 56, 'reg_alpha': 0.6476342328905603, 'reg_lambda': 0.9718600854662549, 'subsample': 0.6162700131718355, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 32%|███▏      | 32/100 [49:45<1:47:28, 94.84s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673859\n",
      "[2000]\tvalid_0's auc: 0.675037\n",
      "Early stopping, best iteration is:\n",
      "[2507]\tvalid_0's auc: 0.675255\n",
      "valid scores:\n",
      "[0.6752548734246762]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "34\n",
      "hyper params\n",
      "subsample: 0.9558055714000018 num_leaves: 69.0 subsample_for_bin: 120000.0\n",
      "min_child_samples: 220.0 reg_alpha: 0.1687027175891639 reg_lambda: 0.7212235857543919 colsample_bytree: 0.7430901784717867\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7430901784717867, 'min_child_samples': 220, 'num_leaves': 69, 'reg_alpha': 0.1687027175891639, 'reg_lambda': 0.7212235857543919, 'subsample': 0.9558055714000018, 'subsample_for_bin': 120000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 33%|███▎      | 33/100 [51:13<1:43:30, 92.70s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674345\n",
      "[2000]\tvalid_0's auc: 0.675694\n",
      "Early stopping, best iteration is:\n",
      "[1780]\tvalid_0's auc: 0.675778\n",
      "valid scores:\n",
      "[0.6757776849476304]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "35\n",
      "hyper params\n",
      "subsample: 0.9710516262095408 num_leaves: 74.0 subsample_for_bin: 130000.0\n",
      "min_child_samples: 35.0 reg_alpha: 0.11263182605208971 reg_lambda: 0.6372968052223319 colsample_bytree: 0.6167470649021697\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6167470649021697, 'min_child_samples': 35, 'num_leaves': 74, 'reg_alpha': 0.11263182605208971, 'reg_lambda': 0.6372968052223319, 'subsample': 0.9710516262095408, 'subsample_for_bin': 130000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 34%|███▍      | 34/100 [52:41<1:40:23, 91.27s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674264\n",
      "[2000]\tvalid_0's auc: 0.675602\n",
      "Early stopping, best iteration is:\n",
      "[2028]\tvalid_0's auc: 0.675638\n",
      "valid scores:\n",
      "[0.6756384744505818]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "36\n",
      "hyper params\n",
      "subsample: 0.8844491833055015 num_leaves: 78.0 subsample_for_bin: 110000.0\n",
      "min_child_samples: 120.0 reg_alpha: 0.2805452366139597 reg_lambda: 0.8016034449005468 colsample_bytree: 0.863148447580756\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.863148447580756, 'min_child_samples': 120, 'num_leaves': 78, 'reg_alpha': 0.2805452366139597, 'reg_lambda': 0.8016034449005468, 'subsample': 0.8844491833055015, 'subsample_for_bin': 110000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 35%|███▌      | 35/100 [54:05<1:36:39, 89.22s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67449\n",
      "[2000]\tvalid_0's auc: 0.675457\n",
      "Early stopping, best iteration is:\n",
      "[2221]\tvalid_0's auc: 0.675543\n",
      "valid scores:\n",
      "[0.6755432611213824]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "37\n",
      "hyper params\n",
      "subsample: 0.8520919967387447 num_leaves: 59.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 190.0 reg_alpha: 0.3493322905373154 reg_lambda: 0.9101042471727052 colsample_bytree: 0.6015875652015369\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6015875652015369, 'min_child_samples': 190, 'num_leaves': 59, 'reg_alpha': 0.3493322905373154, 'reg_lambda': 0.9101042471727052, 'subsample': 0.8520919967387447, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 36%|███▌      | 36/100 [55:51<1:40:33, 94.28s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674288\n",
      "[2000]\tvalid_0's auc: 0.675988\n",
      "Early stopping, best iteration is:\n",
      "[2228]\tvalid_0's auc: 0.676099\n",
      "valid scores:\n",
      "[0.6760993630815699]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "38\n",
      "hyper params\n",
      "subsample: 0.9030676774386487 num_leaves: 80.0 subsample_for_bin: 80000.0\n",
      "min_child_samples: 155.0 reg_alpha: 0.31899064970573776 reg_lambda: 0.15928154169241188 colsample_bytree: 0.9609410967652224\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.9609410967652224, 'min_child_samples': 155, 'num_leaves': 80, 'reg_alpha': 0.31899064970573776, 'reg_lambda': 0.15928154169241188, 'subsample': 0.9030676774386487, 'subsample_for_bin': 80000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 37%|███▋      | 37/100 [57:21<1:37:34, 92.93s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673778\n",
      "Early stopping, best iteration is:\n",
      "[1663]\tvalid_0's auc: 0.675209\n",
      "valid scores:\n",
      "[0.6752090444507549]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "39\n",
      "hyper params\n",
      "subsample: 0.9824744268108278 num_leaves: 54.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 85.0 reg_alpha: 0.45366526875492613 reg_lambda: 0.1090492843922462 colsample_bytree: 0.6293467411822029\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6293467411822029, 'min_child_samples': 85, 'num_leaves': 54, 'reg_alpha': 0.45366526875492613, 'reg_lambda': 0.1090492843922462, 'subsample': 0.9824744268108278, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 38%|███▊      | 38/100 [58:52<1:35:19, 92.25s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67373\n",
      "[2000]\tvalid_0's auc: 0.675866\n",
      "[3000]\tvalid_0's auc: 0.676323\n",
      "Early stopping, best iteration is:\n",
      "[3320]\tvalid_0's auc: 0.67636\n",
      "valid scores:\n",
      "[0.6763596188909339]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "40\n",
      "hyper params\n",
      "subsample: 0.9181869523612656 num_leaves: 73.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 175.0 reg_alpha: 0.4903154106750711 reg_lambda: 0.8369029188292949 colsample_bytree: 0.6492292149467181\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6492292149467181, 'min_child_samples': 175, 'num_leaves': 73, 'reg_alpha': 0.4903154106750711, 'reg_lambda': 0.8369029188292949, 'subsample': 0.9181869523612656, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 39%|███▉      | 39/100 [1:00:49<1:41:21, 99.70s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674779\n",
      "[2000]\tvalid_0's auc: 0.67612\n",
      "Early stopping, best iteration is:\n",
      "[2226]\tvalid_0's auc: 0.676279\n",
      "valid scores:\n",
      "[0.6762793941728658]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "41\n",
      "hyper params\n",
      "subsample: 0.9992321258292132 num_leaves: 75.0 subsample_for_bin: 90000.0\n",
      "min_child_samples: 210.0 reg_alpha: 0.05449742785627465 reg_lambda: 0.9378226718170354 colsample_bytree: 0.7279975765442065\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7279975765442065, 'min_child_samples': 210, 'num_leaves': 75, 'reg_alpha': 0.05449742785627465, 'reg_lambda': 0.9378226718170354, 'subsample': 0.9992321258292132, 'subsample_for_bin': 90000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 40%|████      | 40/100 [1:02:27<1:39:11, 99.19s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674246\n",
      "[2000]\tvalid_0's auc: 0.675555\n",
      "Early stopping, best iteration is:\n",
      "[1894]\tvalid_0's auc: 0.675628\n",
      "valid scores:\n",
      "[0.6756276594891788]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "42\n",
      "hyper params\n",
      "subsample: 0.7784732312622513 num_leaves: 67.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 100.0 reg_alpha: 0.534657303339539 reg_lambda: 0.9591701626591149 colsample_bytree: 0.7074231742358065\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7074231742358065, 'min_child_samples': 100, 'num_leaves': 67, 'reg_alpha': 0.534657303339539, 'reg_lambda': 0.9591701626591149, 'subsample': 0.7784732312622513, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 41%|████      | 41/100 [1:04:01<1:36:07, 97.76s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674517\n",
      "[2000]\tvalid_0's auc: 0.675508\n",
      "Early stopping, best iteration is:\n",
      "[1771]\tvalid_0's auc: 0.675695\n",
      "valid scores:\n",
      "[0.6756947517541146]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "43\n",
      "hyper params\n",
      "subsample: 0.9507716815892242 num_leaves: 63.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 285.0 reg_alpha: 0.3914438597809889 reg_lambda: 0.9897810056364514 colsample_bytree: 0.7186699569019389\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7186699569019389, 'min_child_samples': 285, 'num_leaves': 63, 'reg_alpha': 0.3914438597809889, 'reg_lambda': 0.9897810056364514, 'subsample': 0.9507716815892242, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 42%|████▏     | 42/100 [1:05:17<1:28:16, 91.31s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674048\n",
      "[2000]\tvalid_0's auc: 0.675484\n",
      "Early stopping, best iteration is:\n",
      "[1967]\tvalid_0's auc: 0.675526\n",
      "valid scores:\n",
      "[0.6755260646021938]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "44\n",
      "hyper params\n",
      "subsample: 0.9386325892333665 num_leaves: 71.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 60.0 reg_alpha: 0.24162669817242052 reg_lambda: 0.7529358877562952 colsample_bytree: 0.6747163026957622\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6747163026957622, 'min_child_samples': 60, 'num_leaves': 71, 'reg_alpha': 0.24162669817242052, 'reg_lambda': 0.7529358877562952, 'subsample': 0.9386325892333665, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 43%|████▎     | 43/100 [1:06:52<1:27:42, 92.33s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674183\n",
      "[2000]\tvalid_0's auc: 0.67566\n",
      "Early stopping, best iteration is:\n",
      "[2375]\tvalid_0's auc: 0.67597\n",
      "valid scores:\n",
      "[0.6759699095899802]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "45\n",
      "hyper params\n",
      "subsample: 0.7937370114413391 num_leaves: 45.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 70.0 reg_alpha: 0.42851841542855335 reg_lambda: 0.6638983686023251 colsample_bytree: 0.8745064676001174\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.8745064676001174, 'min_child_samples': 70, 'num_leaves': 45, 'reg_alpha': 0.42851841542855335, 'reg_lambda': 0.6638983686023251, 'subsample': 0.7937370114413391, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 44%|████▍     | 44/100 [1:08:29<1:27:19, 93.55s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673118\n",
      "[2000]\tvalid_0's auc: 0.674967\n",
      "Early stopping, best iteration is:\n",
      "[2579]\tvalid_0's auc: 0.675394\n",
      "valid scores:\n",
      "[0.6753942868544507]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "46\n",
      "hyper params\n",
      "subsample: 0.965757186457139 num_leaves: 33.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 140.0 reg_alpha: 0.6706784476040264 reg_lambda: 0.6937038993798242 colsample_bytree: 0.7843913992684227\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7843913992684227, 'min_child_samples': 140, 'num_leaves': 33, 'reg_alpha': 0.6706784476040264, 'reg_lambda': 0.6937038993798242, 'subsample': 0.965757186457139, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 45%|████▌     | 45/100 [1:10:02<1:25:45, 93.55s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.671801\n",
      "[2000]\tvalid_0's auc: 0.674348\n",
      "[3000]\tvalid_0's auc: 0.67547\n",
      "Early stopping, best iteration is:\n",
      "[3510]\tvalid_0's auc: 0.675728\n",
      "valid scores:\n",
      "[0.6757283993529455]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "47\n",
      "hyper params\n",
      "subsample: 0.89280124224859 num_leaves: 65.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 45.0 reg_alpha: 0.6041232314832636 reg_lambda: 0.8921573229576588 colsample_bytree: 0.7541140153723433\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7541140153723433, 'min_child_samples': 45, 'num_leaves': 65, 'reg_alpha': 0.6041232314832636, 'reg_lambda': 0.8921573229576588, 'subsample': 0.89280124224859, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 46%|████▌     | 46/100 [1:11:57<1:30:03, 100.06s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673491\n",
      "[2000]\tvalid_0's auc: 0.675428\n",
      "Early stopping, best iteration is:\n",
      "[2482]\tvalid_0's auc: 0.675691\n",
      "valid scores:\n",
      "[0.6756911584919822]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "48\n",
      "hyper params\n",
      "subsample: 0.9263436224780116 num_leaves: 27.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 110.0 reg_alpha: 0.20002137135141193 reg_lambda: 0.8506383010714899 colsample_bytree: 0.6599683618867518\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6599683618867518, 'min_child_samples': 110, 'num_leaves': 27, 'reg_alpha': 0.20002137135141193, 'reg_lambda': 0.8506383010714899, 'subsample': 0.9263436224780116, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 47%|████▋     | 47/100 [1:13:35<1:27:38, 99.21s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.671276\n",
      "[2000]\tvalid_0's auc: 0.673899\n",
      "[3000]\tvalid_0's auc: 0.675142\n",
      "[4000]\tvalid_0's auc: 0.67545\n",
      "Early stopping, best iteration is:\n",
      "[4067]\tvalid_0's auc: 0.675518\n",
      "valid scores:\n",
      "[0.6755177240671614]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "49\n",
      "hyper params\n",
      "subsample: 0.9877609837124003 num_leaves: 77.0 subsample_for_bin: 130000.0\n",
      "min_child_samples: 125.0 reg_alpha: 0.002990672771963354 reg_lambda: 0.9227889048111979 colsample_bytree: 0.6150644864053576\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6150644864053576, 'min_child_samples': 125, 'num_leaves': 77, 'reg_alpha': 0.002990672771963354, 'reg_lambda': 0.9227889048111979, 'subsample': 0.9877609837124003, 'subsample_for_bin': 130000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 48%|████▊     | 48/100 [1:15:30<1:30:15, 104.14s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674921\n",
      "Early stopping, best iteration is:\n",
      "[1608]\tvalid_0's auc: 0.675792\n",
      "valid scores:\n",
      "[0.67579226769331]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "50\n",
      "hyper params\n",
      "subsample: 0.9582632322173968 num_leaves: 79.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 95.0 reg_alpha: 0.08658770484743555 reg_lambda: 0.8096661567054807 colsample_bytree: 0.6415605265627901\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6415605265627901, 'min_child_samples': 95, 'num_leaves': 79, 'reg_alpha': 0.08658770484743555, 'reg_lambda': 0.8096661567054807, 'subsample': 0.9582632322173968, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 49%|████▉     | 49/100 [1:16:48<1:21:50, 96.28s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674507\n",
      "[2000]\tvalid_0's auc: 0.675828\n",
      "Early stopping, best iteration is:\n",
      "[2237]\tvalid_0's auc: 0.675858\n",
      "valid scores:\n",
      "[0.6758577270262451]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "51\n",
      "hyper params\n",
      "subsample: 0.8041341213584793 num_leaves: 68.0 subsample_for_bin: 80000.0\n",
      "min_child_samples: 165.0 reg_alpha: 0.3722859895683779 reg_lambda: 0.8716498453100413 colsample_bytree: 0.6261286650471038\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6261286650471038, 'min_child_samples': 165, 'num_leaves': 68, 'reg_alpha': 0.3722859895683779, 'reg_lambda': 0.8716498453100413, 'subsample': 0.8041341213584793, 'subsample_for_bin': 80000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 50%|█████     | 50/100 [1:18:26<1:20:33, 96.67s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675054\n",
      "[2000]\tvalid_0's auc: 0.676244\n",
      "Early stopping, best iteration is:\n",
      "[1874]\tvalid_0's auc: 0.676355\n",
      "valid scores:\n",
      "[0.6763549771430513]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "52\n",
      "hyper params\n",
      "subsample: 0.9765972750433711 num_leaves: 61.0 subsample_for_bin: 90000.0\n",
      "min_child_samples: 270.0 reg_alpha: 0.707883821324174 reg_lambda: 0.5297700265378352 colsample_bytree: 0.776478783933451\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.776478783933451, 'min_child_samples': 270, 'num_leaves': 61, 'reg_alpha': 0.707883821324174, 'reg_lambda': 0.5297700265378352, 'subsample': 0.9765972750433711, 'subsample_for_bin': 90000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 51%|█████     | 51/100 [1:19:45<1:14:45, 91.55s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674044\n",
      "[2000]\tvalid_0's auc: 0.67567\n",
      "Early stopping, best iteration is:\n",
      "[1826]\tvalid_0's auc: 0.675825\n",
      "valid scores:\n",
      "[0.6758246909313615]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "53\n",
      "hyper params\n",
      "subsample: 0.9915865436719244 num_leaves: 70.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 80.0 reg_alpha: 0.27016000968086096 reg_lambda: 0.8251341143514178 colsample_bytree: 0.6017009475847273\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6017009475847273, 'min_child_samples': 80, 'num_leaves': 70, 'reg_alpha': 0.27016000968086096, 'reg_lambda': 0.8251341143514178, 'subsample': 0.9915865436719244, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 52%|█████▏    | 52/100 [1:21:13<1:12:22, 90.46s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674838\n",
      "[2000]\tvalid_0's auc: 0.67639\n",
      "Early stopping, best iteration is:\n",
      "[2148]\tvalid_0's auc: 0.676567\n",
      "valid scores:\n",
      "[0.6765674734118287]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "54\n",
      "hyper params\n",
      "subsample: 0.8442140600124836 num_leaves: 31.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 145.0 reg_alpha: 0.5706266551294792 reg_lambda: 0.9988621624194067 colsample_bytree: 0.6928115645646062\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6928115645646062, 'min_child_samples': 145, 'num_leaves': 31, 'reg_alpha': 0.5706266551294792, 'reg_lambda': 0.9988621624194067, 'subsample': 0.8442140600124836, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 53%|█████▎    | 53/100 [1:22:42<1:10:33, 90.08s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.671736\n",
      "[2000]\tvalid_0's auc: 0.674457\n",
      "[3000]\tvalid_0's auc: 0.675386\n",
      "Early stopping, best iteration is:\n",
      "[3697]\tvalid_0's auc: 0.675705\n",
      "valid scores:\n",
      "[0.6757052163183443]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "55\n",
      "hyper params\n",
      "subsample: 0.9093019057423344 num_leaves: 72.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 35.0 reg_alpha: 0.3352996070884483 reg_lambda: 0.741402815009461 colsample_bytree: 0.6821632016839538\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6821632016839538, 'min_child_samples': 35, 'num_leaves': 72, 'reg_alpha': 0.3352996070884483, 'reg_lambda': 0.741402815009461, 'subsample': 0.9093019057423344, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 54%|█████▍    | 54/100 [1:24:31<1:13:21, 95.69s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673962\n",
      "[2000]\tvalid_0's auc: 0.675726\n",
      "Early stopping, best iteration is:\n",
      "[2626]\tvalid_0's auc: 0.676061\n",
      "valid scores:\n",
      "[0.6760612671973885]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "56\n",
      "hyper params\n",
      "subsample: 0.9321225602766994 num_leaves: 52.0 subsample_for_bin: 120000.0\n",
      "min_child_samples: 50.0 reg_alpha: 0.4002415433622633 reg_lambda: 0.8994157361499757 colsample_bytree: 0.8311840836010572\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.8311840836010572, 'min_child_samples': 50, 'num_leaves': 52, 'reg_alpha': 0.4002415433622633, 'reg_lambda': 0.8994157361499757, 'subsample': 0.9321225602766994, 'subsample_for_bin': 120000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 55%|█████▌    | 55/100 [1:26:12<1:12:58, 97.30s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673106\n",
      "[2000]\tvalid_0's auc: 0.675346\n",
      "Early stopping, best iteration is:\n",
      "[2600]\tvalid_0's auc: 0.676002\n",
      "valid scores:\n",
      "[0.6760022354203233]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "57\n",
      "hyper params\n",
      "subsample: 0.9481966162754648 num_leaves: 62.0 subsample_for_bin: 110000.0\n",
      "min_child_samples: 185.0 reg_alpha: 0.4581317205172713 reg_lambda: 0.7747514394108086 colsample_bytree: 0.6533252459482727\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6533252459482727, 'min_child_samples': 185, 'num_leaves': 62, 'reg_alpha': 0.4581317205172713, 'reg_lambda': 0.7747514394108086, 'subsample': 0.9481966162754648, 'subsample_for_bin': 110000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 56%|█████▌    | 56/100 [1:27:51<1:11:43, 97.80s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674514\n",
      "[2000]\tvalid_0's auc: 0.676122\n",
      "Early stopping, best iteration is:\n",
      "[2256]\tvalid_0's auc: 0.676258\n",
      "valid scores:\n",
      "[0.6762583771068919]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "58\n",
      "hyper params\n",
      "subsample: 0.9991008084182967 num_leaves: 58.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 175.0 reg_alpha: 0.4261265613387802 reg_lambda: 0.9396368150842379 colsample_bytree: 0.6089335138839751\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6089335138839751, 'min_child_samples': 175, 'num_leaves': 58, 'reg_alpha': 0.4261265613387802, 'reg_lambda': 0.9396368150842379, 'subsample': 0.9991008084182967, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 57%|█████▋    | 57/100 [1:29:25<1:09:18, 96.72s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673975\n",
      "[2000]\tvalid_0's auc: 0.676048\n",
      "Early stopping, best iteration is:\n",
      "[2180]\tvalid_0's auc: 0.676206\n",
      "valid scores:\n",
      "[0.6762062775117419]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "59\n",
      "hyper params\n",
      "subsample: 0.9709249074964781 num_leaves: 66.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 115.0 reg_alpha: 0.35377728366247657 reg_lambda: 0.787458129848984 colsample_bytree: 0.6186573498857353\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6186573498857353, 'min_child_samples': 115, 'num_leaves': 66, 'reg_alpha': 0.35377728366247657, 'reg_lambda': 0.787458129848984, 'subsample': 0.9709249074964781, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 58%|█████▊    | 58/100 [1:30:55<1:06:12, 94.57s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674766\n",
      "[2000]\tvalid_0's auc: 0.67618\n",
      "Early stopping, best iteration is:\n",
      "[2450]\tvalid_0's auc: 0.676311\n",
      "valid scores:\n",
      "[0.6763108744501846]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "60\n",
      "hyper params\n",
      "subsample: 0.9807129675139453 num_leaves: 63.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 200.0 reg_alpha: 0.5140425396971745 reg_lambda: 0.8617935374117125 colsample_bytree: 0.6007608766010716\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6007608766010716, 'min_child_samples': 200, 'num_leaves': 63, 'reg_alpha': 0.5140425396971745, 'reg_lambda': 0.8617935374117125, 'subsample': 0.9807129675139453, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 59%|█████▉    | 59/100 [1:32:35<1:05:45, 96.22s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674771\n",
      "[2000]\tvalid_0's auc: 0.676633\n",
      "Early stopping, best iteration is:\n",
      "[2193]\tvalid_0's auc: 0.676666\n",
      "valid scores:\n",
      "[0.6766657442607642]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "61\n",
      "hyper params\n",
      "subsample: 0.9655235948953964 num_leaves: 65.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 130.0 reg_alpha: 0.48240532489698074 reg_lambda: 0.9703116091896449 colsample_bytree: 0.6325656074509228\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6325656074509228, 'min_child_samples': 130, 'num_leaves': 65, 'reg_alpha': 0.48240532489698074, 'reg_lambda': 0.9703116091896449, 'subsample': 0.9655235948953964, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 60%|██████    | 60/100 [1:34:08<1:03:34, 95.37s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674814\n",
      "[2000]\tvalid_0's auc: 0.676607\n",
      "Early stopping, best iteration is:\n",
      "[2261]\tvalid_0's auc: 0.676697\n",
      "valid scores:\n",
      "[0.6766967740274316]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "62\n",
      "hyper params\n",
      "subsample: 0.6367199717090065 num_leaves: 60.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 160.0 reg_alpha: 0.4127679150215115 reg_lambda: 0.8386891467244246 colsample_bytree: 0.6000391343515132\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6000391343515132, 'min_child_samples': 160, 'num_leaves': 60, 'reg_alpha': 0.4127679150215115, 'reg_lambda': 0.8386891467244246, 'subsample': 0.6367199717090065, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 61%|██████    | 61/100 [1:35:42<1:01:42, 94.93s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674032\n",
      "[2000]\tvalid_0's auc: 0.674876\n",
      "Early stopping, best iteration is:\n",
      "[1713]\tvalid_0's auc: 0.675018\n",
      "valid scores:\n",
      "[0.6750179102335854]\n",
      "CV score: 0.50701 \n",
      "ITERATION:\n",
      "63\n",
      "hyper params\n",
      "subsample: 0.9438985585150789 num_leaves: 57.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 105.0 reg_alpha: 0.2937994536253624 reg_lambda: 0.8777365144919314 colsample_bytree: 0.6394931451207944\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6394931451207944, 'min_child_samples': 105, 'num_leaves': 57, 'reg_alpha': 0.2937994536253624, 'reg_lambda': 0.8777365144919314, 'subsample': 0.9438985585150789, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 62%|██████▏   | 62/100 [1:36:50<54:55, 86.72s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674099\n",
      "[2000]\tvalid_0's auc: 0.675991\n",
      "Early stopping, best iteration is:\n",
      "[2526]\tvalid_0's auc: 0.676204\n",
      "valid scores:\n",
      "[0.6762037909094077]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "64\n",
      "hyper params\n",
      "subsample: 0.9537020143680547 num_leaves: 73.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 150.0 reg_alpha: 0.3072947773984835 reg_lambda: 0.7930688857445191 colsample_bytree: 0.62135882790539\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.62135882790539, 'min_child_samples': 150, 'num_leaves': 73, 'reg_alpha': 0.3072947773984835, 'reg_lambda': 0.7930688857445191, 'subsample': 0.9537020143680547, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 63%|██████▎   | 63/100 [1:38:26<55:15, 89.61s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675108\n",
      "[2000]\tvalid_0's auc: 0.676758\n",
      "Early stopping, best iteration is:\n",
      "[2054]\tvalid_0's auc: 0.676803\n",
      "valid scores:\n",
      "[0.6768030742478867]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "65\n",
      "hyper params\n",
      "subsample: 0.9569657566841793 num_leaves: 73.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 90.0 reg_alpha: 0.315398105430718 reg_lambda: 0.7085155400897722 colsample_bytree: 0.6701826019497669\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6701826019497669, 'min_child_samples': 90, 'num_leaves': 73, 'reg_alpha': 0.315398105430718, 'reg_lambda': 0.7085155400897722, 'subsample': 0.9569657566841793, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 64%|██████▍   | 64/100 [1:39:57<53:55, 89.86s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674245\n",
      "[2000]\tvalid_0's auc: 0.676002\n",
      "Early stopping, best iteration is:\n",
      "[2191]\tvalid_0's auc: 0.676068\n",
      "valid scores:\n",
      "[0.6760679274494509]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "66\n",
      "hyper params\n",
      "subsample: 0.9900273499889352 num_leaves: 76.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 140.0 reg_alpha: 0.25271298660254465 reg_lambda: 0.903210304934033 colsample_bytree: 0.6263007294472083\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6263007294472083, 'min_child_samples': 140, 'num_leaves': 76, 'reg_alpha': 0.25271298660254465, 'reg_lambda': 0.903210304934033, 'subsample': 0.9900273499889352, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 65%|██████▌   | 65/100 [1:41:29<52:53, 90.68s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675191\n",
      "[2000]\tvalid_0's auc: 0.676748\n",
      "Early stopping, best iteration is:\n",
      "[1979]\tvalid_0's auc: 0.676799\n",
      "valid scores:\n",
      "[0.6767994268703607]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "67\n",
      "hyper params\n",
      "subsample: 0.9387171737123099 num_leaves: 74.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 70.0 reg_alpha: 0.1834413753728028 reg_lambda: 0.8236573879432695 colsample_bytree: 0.6119188422085918\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6119188422085918, 'min_child_samples': 70, 'num_leaves': 74, 'reg_alpha': 0.1834413753728028, 'reg_lambda': 0.8236573879432695, 'subsample': 0.9387171737123099, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 66%|██████▌   | 66/100 [1:42:59<51:11, 90.35s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674459\n",
      "Early stopping, best iteration is:\n",
      "[1624]\tvalid_0's auc: 0.675584\n",
      "valid scores:\n",
      "[0.6755842413560407]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "68\n",
      "hyper params\n",
      "subsample: 0.998919644813132 num_leaves: 78.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 150.0 reg_alpha: 0.3671714662468187 reg_lambda: 0.7947117046828232 colsample_bytree: 0.6474458077261958\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6474458077261958, 'min_child_samples': 150, 'num_leaves': 78, 'reg_alpha': 0.3671714662468187, 'reg_lambda': 0.7947117046828232, 'subsample': 0.998919644813132, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 67%|██████▋   | 67/100 [1:44:11<46:42, 84.93s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674999\n",
      "[2000]\tvalid_0's auc: 0.676319\n",
      "Early stopping, best iteration is:\n",
      "[1758]\tvalid_0's auc: 0.676394\n",
      "valid scores:\n",
      "[0.6763938834052513]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "69\n",
      "hyper params\n",
      "subsample: 0.9711153190142209 num_leaves: 69.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 100.0 reg_alpha: 0.22572032236055523 reg_lambda: 0.754538974011744 colsample_bytree: 0.6627571516142237\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6627571516142237, 'min_child_samples': 100, 'num_leaves': 69, 'reg_alpha': 0.22572032236055523, 'reg_lambda': 0.754538974011744, 'subsample': 0.9711153190142209, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 68%|██████▊   | 68/100 [1:45:36<45:13, 84.79s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674588\n",
      "[2000]\tvalid_0's auc: 0.676133\n",
      "[3000]\tvalid_0's auc: 0.676404\n",
      "Early stopping, best iteration is:\n",
      "[2702]\tvalid_0's auc: 0.676561\n",
      "valid scores:\n",
      "[0.6765605574645317]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "70\n",
      "hyper params\n",
      "subsample: 0.9196310184739287 num_leaves: 80.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 80.0 reg_alpha: 0.33879416777803484 reg_lambda: 0.9165060236526589 colsample_bytree: 0.6335915291433594\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6335915291433594, 'min_child_samples': 80, 'num_leaves': 80, 'reg_alpha': 0.33879416777803484, 'reg_lambda': 0.9165060236526589, 'subsample': 0.9196310184739287, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 69%|██████▉   | 69/100 [1:47:25<47:41, 92.30s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674711\n",
      "[2000]\tvalid_0's auc: 0.676201\n",
      "Early stopping, best iteration is:\n",
      "[2054]\tvalid_0's auc: 0.676239\n",
      "valid scores:\n",
      "[0.6762388157450047]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "71\n",
      "hyper params\n",
      "subsample: 0.9835332882410699 num_leaves: 75.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 115.0 reg_alpha: 0.30009881153273427 reg_lambda: 0.9497172483671844 colsample_bytree: 0.6079252892666447\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6079252892666447, 'min_child_samples': 115, 'num_leaves': 75, 'reg_alpha': 0.30009881153273427, 'reg_lambda': 0.9497172483671844, 'subsample': 0.9835332882410699, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 70%|███████   | 70/100 [1:48:54<45:37, 91.25s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675066\n",
      "[2000]\tvalid_0's auc: 0.676607\n",
      "Early stopping, best iteration is:\n",
      "[2175]\tvalid_0's auc: 0.67682\n",
      "valid scores:\n",
      "[0.6768204493478739]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "72\n",
      "hyper params\n",
      "subsample: 0.9995507347503901 num_leaves: 75.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 115.0 reg_alpha: 0.14726423054208995 reg_lambda: 0.9801757189055275 colsample_bytree: 0.6068343762132014\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6068343762132014, 'min_child_samples': 115, 'num_leaves': 75, 'reg_alpha': 0.14726423054208995, 'reg_lambda': 0.9801757189055275, 'subsample': 0.9995507347503901, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 71%|███████   | 71/100 [1:50:28<44:30, 92.08s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673967\n",
      "[2000]\tvalid_0's auc: 0.675623\n",
      "Early stopping, best iteration is:\n",
      "[2065]\tvalid_0's auc: 0.675687\n",
      "valid scores:\n",
      "[0.6756870213701446]\n",
      "CV score: 0.50703 \n",
      "ITERATION:\n",
      "73\n",
      "hyper params\n",
      "subsample: 0.9816339214653931 num_leaves: 76.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 60.0 reg_alpha: 0.9947220139850945 reg_lambda: 0.9401233793988979 colsample_bytree: 0.641796631910236\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.641796631910236, 'min_child_samples': 60, 'num_leaves': 76, 'reg_alpha': 0.9947220139850945, 'reg_lambda': 0.9401233793988979, 'subsample': 0.9816339214653931, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 72%|███████▏  | 72/100 [1:51:58<42:40, 91.46s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675096\n",
      "[2000]\tvalid_0's auc: 0.676839\n",
      "Early stopping, best iteration is:\n",
      "[2526]\tvalid_0's auc: 0.677043\n",
      "valid scores:\n",
      "[0.677042755384619]\n",
      "CV score: 0.50709 \n",
      "ITERATION:\n",
      "74\n",
      "hyper params\n",
      "subsample: 0.9613852649952479 num_leaves: 79.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 55.0 reg_alpha: 0.9553704714594069 reg_lambda: 0.9319997152348244 colsample_bytree: 0.6539083261588421\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6539083261588421, 'min_child_samples': 55, 'num_leaves': 79, 'reg_alpha': 0.9553704714594069, 'reg_lambda': 0.9319997152348244, 'subsample': 0.9613852649952479, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 73%|███████▎  | 73/100 [1:53:42<42:46, 95.04s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674791\n",
      "[2000]\tvalid_0's auc: 0.676391\n",
      "Early stopping, best iteration is:\n",
      "[2395]\tvalid_0's auc: 0.676514\n",
      "valid scores:\n",
      "[0.6765137138269812]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "75\n",
      "hyper params\n",
      "subsample: 0.9926425280358904 num_leaves: 77.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 30.0 reg_alpha: 0.8493804959871396 reg_lambda: 0.9661296949754138 colsample_bytree: 0.6421097759133325\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6421097759133325, 'min_child_samples': 30, 'num_leaves': 77, 'reg_alpha': 0.8493804959871396, 'reg_lambda': 0.9661296949754138, 'subsample': 0.9926425280358904, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 74%|███████▍  | 74/100 [1:55:21<41:45, 96.36s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673773\n",
      "[2000]\tvalid_0's auc: 0.675225\n",
      "Early stopping, best iteration is:\n",
      "[2016]\tvalid_0's auc: 0.675244\n",
      "valid scores:\n",
      "[0.6752444616229553]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "76\n",
      "hyper params\n",
      "subsample: 0.9790612031446044 num_leaves: 71.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 65.0 reg_alpha: 0.9196939216131436 reg_lambda: 0.8793812558706353 colsample_bytree: 0.6813627922808398\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6813627922808398, 'min_child_samples': 65, 'num_leaves': 71, 'reg_alpha': 0.9196939216131436, 'reg_lambda': 0.8793812558706353, 'subsample': 0.9790612031446044, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 75%|███████▌  | 75/100 [1:56:48<38:54, 93.40s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674417\n",
      "[2000]\tvalid_0's auc: 0.675744\n",
      "Early stopping, best iteration is:\n",
      "[2621]\tvalid_0's auc: 0.675954\n",
      "valid scores:\n",
      "[0.675954095719097]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "77\n",
      "hyper params\n",
      "subsample: 0.9337833915087794 num_leaves: 77.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 75.0 reg_alpha: 0.9038108842937329 reg_lambda: 0.8474324814718562 colsample_bytree: 0.6992637080494288\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6992637080494288, 'min_child_samples': 75, 'num_leaves': 77, 'reg_alpha': 0.9038108842937329, 'reg_lambda': 0.8474324814718562, 'subsample': 0.9337833915087794, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 76%|███████▌  | 76/100 [1:58:35<39:02, 97.62s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67491\n",
      "[2000]\tvalid_0's auc: 0.67635\n",
      "Early stopping, best iteration is:\n",
      "[2185]\tvalid_0's auc: 0.676475\n",
      "valid scores:\n",
      "[0.6764748955022957]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "78\n",
      "hyper params\n",
      "subsample: 0.9457404464101367 num_leaves: 67.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 45.0 reg_alpha: 0.990660779781453 reg_lambda: 0.9991361689838076 colsample_bytree: 0.6578925018600152\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6578925018600152, 'min_child_samples': 45, 'num_leaves': 67, 'reg_alpha': 0.990660779781453, 'reg_lambda': 0.9991361689838076, 'subsample': 0.9457404464101367, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 77%|███████▋  | 77/100 [2:00:09<37:00, 96.56s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674548\n",
      "[2000]\tvalid_0's auc: 0.676408\n",
      "Early stopping, best iteration is:\n",
      "[2486]\tvalid_0's auc: 0.676773\n",
      "valid scores:\n",
      "[0.6767729035630919]\n",
      "CV score: 0.50708 \n",
      "ITERATION:\n",
      "79\n",
      "hyper params\n",
      "subsample: 0.999893403077867 num_leaves: 72.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 60.0 reg_alpha: 0.3952223227168405 reg_lambda: 0.95463194328434 colsample_bytree: 0.6354621826550974\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6354621826550974, 'min_child_samples': 60, 'num_leaves': 72, 'reg_alpha': 0.3952223227168405, 'reg_lambda': 0.95463194328434, 'subsample': 0.999893403077867, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 78%|███████▊  | 78/100 [2:01:46<35:27, 96.71s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673431\n",
      "[2000]\tvalid_0's auc: 0.67495\n",
      "[3000]\tvalid_0's auc: 0.674987\n",
      "Early stopping, best iteration is:\n",
      "[2736]\tvalid_0's auc: 0.67519\n",
      "valid scores:\n",
      "[0.67519038952171]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "80\n",
      "hyper params\n",
      "subsample: 0.9725811309137842 num_leaves: 76.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 85.0 reg_alpha: 0.46072605709857184 reg_lambda: 0.8997066908777588 colsample_bytree: 0.6240568438323297\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6240568438323297, 'min_child_samples': 85, 'num_leaves': 76, 'reg_alpha': 0.46072605709857184, 'reg_lambda': 0.8997066908777588, 'subsample': 0.9725811309137842, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 79%|███████▉  | 79/100 [2:03:37<35:16, 100.81s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674528\n",
      "[2000]\tvalid_0's auc: 0.675991\n",
      "Early stopping, best iteration is:\n",
      "[2068]\tvalid_0's auc: 0.676044\n",
      "valid scores:\n",
      "[0.6760437662791111]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "81\n",
      "hyper params\n",
      "subsample: 0.8972194289912961 num_leaves: 80.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 35.0 reg_alpha: 0.4960533131897228 reg_lambda: 0.918692818975201 colsample_bytree: 0.6738556994833442\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6738556994833442, 'min_child_samples': 35, 'num_leaves': 80, 'reg_alpha': 0.4960533131897228, 'reg_lambda': 0.918692818975201, 'subsample': 0.8972194289912961, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 80%|████████  | 80/100 [2:05:07<32:34, 97.70s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674767\n",
      "[2000]\tvalid_0's auc: 0.676265\n",
      "Early stopping, best iteration is:\n",
      "[2219]\tvalid_0's auc: 0.676293\n",
      "valid scores:\n",
      "[0.6762925509779251]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "82\n",
      "hyper params\n",
      "subsample: 0.9236923650184989 num_leaves: 68.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 125.0 reg_alpha: 0.43472313236187304 reg_lambda: 0.982884528823267 colsample_bytree: 0.6682603804424592\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6682603804424592, 'min_child_samples': 125, 'num_leaves': 68, 'reg_alpha': 0.43472313236187304, 'reg_lambda': 0.982884528823267, 'subsample': 0.9236923650184989, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 81%|████████  | 81/100 [2:06:41<30:36, 96.66s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674165\n",
      "[2000]\tvalid_0's auc: 0.675866\n",
      "Early stopping, best iteration is:\n",
      "[2227]\tvalid_0's auc: 0.675991\n",
      "valid scores:\n",
      "[0.6759908373655548]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "83\n",
      "hyper params\n",
      "subsample: 0.9654898863607886 num_leaves: 70.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 90.0 reg_alpha: 0.5537595926662169 reg_lambda: 0.7277917522708196 colsample_bytree: 0.6450418013466388\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6450418013466388, 'min_child_samples': 90, 'num_leaves': 70, 'reg_alpha': 0.5537595926662169, 'reg_lambda': 0.7277917522708196, 'subsample': 0.9654898863607886, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 82%|████████▏ | 82/100 [2:08:17<28:52, 96.24s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674641\n",
      "[2000]\tvalid_0's auc: 0.676091\n",
      "Early stopping, best iteration is:\n",
      "[2258]\tvalid_0's auc: 0.676269\n",
      "valid scores:\n",
      "[0.6762690297221142]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "84\n",
      "hyper params\n",
      "subsample: 0.9843617521848336 num_leaves: 78.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 135.0 reg_alpha: 0.27022969269312175 reg_lambda: 0.857072263024627 colsample_bytree: 0.6167154754639689\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6167154754639689, 'min_child_samples': 135, 'num_leaves': 78, 'reg_alpha': 0.27022969269312175, 'reg_lambda': 0.857072263024627, 'subsample': 0.9843617521848336, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 83%|████████▎ | 83/100 [2:09:50<27:03, 95.51s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675003\n",
      "[2000]\tvalid_0's auc: 0.676024\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's auc: 0.676086\n",
      "valid scores:\n",
      "[0.6760862549803648]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "85\n",
      "hyper params\n",
      "subsample: 0.7203400794556631 num_leaves: 73.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 50.0 reg_alpha: 0.5369596358448598 reg_lambda: 0.8173005908997106 colsample_bytree: 0.6890326857268456\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6890326857268456, 'min_child_samples': 50, 'num_leaves': 73, 'reg_alpha': 0.5369596358448598, 'reg_lambda': 0.8173005908997106, 'subsample': 0.7203400794556631, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 84%|████████▍ | 84/100 [2:11:16<24:40, 92.53s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674421\n",
      "[2000]\tvalid_0's auc: 0.675748\n",
      "Early stopping, best iteration is:\n",
      "[1920]\tvalid_0's auc: 0.675819\n",
      "valid scores:\n",
      "[0.6758194620314588]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "86\n",
      "hyper params\n",
      "subsample: 0.7347060537156924 num_leaves: 74.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 100.0 reg_alpha: 0.3767320922225843 reg_lambda: 0.998523198904107 colsample_bytree: 0.6646471960031686\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6646471960031686, 'min_child_samples': 100, 'num_leaves': 74, 'reg_alpha': 0.3767320922225843, 'reg_lambda': 0.998523198904107, 'subsample': 0.7347060537156924, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 85%|████████▌ | 85/100 [2:12:36<22:10, 88.68s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674949\n",
      "Early stopping, best iteration is:\n",
      "[1694]\tvalid_0's auc: 0.67583\n",
      "valid scores:\n",
      "[0.6758299428303066]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "87\n",
      "hyper params\n",
      "subsample: 0.9497394852916787 num_leaves: 69.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 70.0 reg_alpha: 0.6218287504834322 reg_lambda: 0.9409460338491709 colsample_bytree: 0.9402676575013342\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.9402676575013342, 'min_child_samples': 70, 'num_leaves': 69, 'reg_alpha': 0.6218287504834322, 'reg_lambda': 0.9409460338491709, 'subsample': 0.9497394852916787, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 86%|████████▌ | 86/100 [2:13:50<19:42, 84.45s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67347\n",
      "[2000]\tvalid_0's auc: 0.67511\n",
      "Early stopping, best iteration is:\n",
      "[2357]\tvalid_0's auc: 0.675299\n",
      "valid scores:\n",
      "[0.67529937792434]\n",
      "CV score: 0.50702 \n",
      "ITERATION:\n",
      "88\n",
      "hyper params\n",
      "subsample: 0.9565891563295619 num_leaves: 36.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 60.0 reg_alpha: 0.3530492126506948 reg_lambda: 0.8906870985765999 colsample_bytree: 0.6000354084152331\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6000354084152331, 'min_child_samples': 60, 'num_leaves': 36, 'reg_alpha': 0.3530492126506948, 'reg_lambda': 0.8906870985765999, 'subsample': 0.9565891563295619, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 87%|████████▋ | 87/100 [2:15:36<19:41, 90.92s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.6722\n",
      "[2000]\tvalid_0's auc: 0.674468\n",
      "[3000]\tvalid_0's auc: 0.675477\n",
      "[4000]\tvalid_0's auc: 0.675851\n",
      "Early stopping, best iteration is:\n",
      "[4133]\tvalid_0's auc: 0.67588\n",
      "valid scores:\n",
      "[0.6758797817548906]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "89\n",
      "hyper params\n",
      "subsample: 0.9912240262919729 num_leaves: 79.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 40.0 reg_alpha: 0.7534297694617993 reg_lambda: 0.7679386160639712 colsample_bytree: 0.6299869988950781\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6299869988950781, 'min_child_samples': 40, 'num_leaves': 79, 'reg_alpha': 0.7534297694617993, 'reg_lambda': 0.7679386160639712, 'subsample': 0.9912240262919729, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 88%|████████▊ | 88/100 [2:17:34<19:49, 99.08s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674148\n",
      "[2000]\tvalid_0's auc: 0.675715\n",
      "Early stopping, best iteration is:\n",
      "[2250]\tvalid_0's auc: 0.675826\n",
      "valid scores:\n",
      "[0.6758264523874219]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "90\n",
      "hyper params\n",
      "subsample: 0.7035898143953268 num_leaves: 67.0 subsample_for_bin: 140000.0\n",
      "min_child_samples: 105.0 reg_alpha: 0.41187696862112094 reg_lambda: 0.828185359179134 colsample_bytree: 0.6482741045575645\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6482741045575645, 'min_child_samples': 105, 'num_leaves': 67, 'reg_alpha': 0.41187696862112094, 'reg_lambda': 0.828185359179134, 'subsample': 0.7035898143953268, 'subsample_for_bin': 140000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 89%|████████▉ | 89/100 [2:19:08<17:52, 97.52s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67398\n",
      "Early stopping, best iteration is:\n",
      "[1666]\tvalid_0's auc: 0.675059\n",
      "valid scores:\n",
      "[0.6750586320672394]\n",
      "CV score: 0.50701 \n",
      "ITERATION:\n",
      "91\n",
      "hyper params\n",
      "subsample: 0.9132128725256485 num_leaves: 76.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 125.0 reg_alpha: 0.46663357014494933 reg_lambda: 0.8637832859081718 colsample_bytree: 0.6145957938439519\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6145957938439519, 'min_child_samples': 125, 'num_leaves': 76, 'reg_alpha': 0.46663357014494933, 'reg_lambda': 0.8637832859081718, 'subsample': 0.9132128725256485, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 90%|█████████ | 90/100 [2:20:18<14:53, 89.31s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.6749\n",
      "Early stopping, best iteration is:\n",
      "[1688]\tvalid_0's auc: 0.676283\n",
      "valid scores:\n",
      "[0.6762832607177357]\n",
      "CV score: 0.50706 \n",
      "ITERATION:\n",
      "92\n",
      "hyper params\n",
      "subsample: 0.9748376682617402 num_leaves: 71.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 170.0 reg_alpha: 0.5776510464082423 reg_lambda: 0.9997949842230387 colsample_bytree: 0.7115174993169148\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7115174993169148, 'min_child_samples': 170, 'num_leaves': 71, 'reg_alpha': 0.5776510464082423, 'reg_lambda': 0.9997949842230387, 'subsample': 0.9748376682617402, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 91%|█████████ | 91/100 [2:21:36<12:51, 85.76s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674661\n",
      "[2000]\tvalid_0's auc: 0.676454\n",
      "Early stopping, best iteration is:\n",
      "[1843]\tvalid_0's auc: 0.676506\n",
      "valid scores:\n",
      "[0.6765061336132282]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "93\n",
      "hyper params\n",
      "subsample: 0.9398132606691418 num_leaves: 64.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 95.0 reg_alpha: 0.4417689695973221 reg_lambda: 0.6716677209442954 colsample_bytree: 0.734285776784449\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.734285776784449, 'min_child_samples': 95, 'num_leaves': 64, 'reg_alpha': 0.4417689695973221, 'reg_lambda': 0.6716677209442954, 'subsample': 0.9398132606691418, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 92%|█████████▏| 92/100 [2:23:04<11:31, 86.49s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.673759\n",
      "[2000]\tvalid_0's auc: 0.675357\n",
      "Early stopping, best iteration is:\n",
      "[2418]\tvalid_0's auc: 0.675813\n",
      "valid scores:\n",
      "[0.6758132982881323]\n",
      "CV score: 0.50704 \n",
      "ITERATION:\n",
      "94\n",
      "hyper params\n",
      "subsample: 0.9318998549226152 num_leaves: 74.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 30.0 reg_alpha: 0.945721146400458 reg_lambda: 0.9557554371336379 colsample_bytree: 0.6007487388451533\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6007487388451533, 'min_child_samples': 30, 'num_leaves': 74, 'reg_alpha': 0.945721146400458, 'reg_lambda': 0.9557554371336379, 'subsample': 0.9318998549226152, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 93%|█████████▎| 93/100 [2:24:43<10:30, 90.09s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674746\n",
      "[2000]\tvalid_0's auc: 0.676451\n",
      "Early stopping, best iteration is:\n",
      "[2188]\tvalid_0's auc: 0.67657\n",
      "valid scores:\n",
      "[0.676570176475737]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "95\n",
      "hyper params\n",
      "subsample: 0.9670191838814417 num_leaves: 77.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 80.0 reg_alpha: 0.507867504674038 reg_lambda: 0.9233584825228354 colsample_bytree: 0.7021703839888747\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.7021703839888747, 'min_child_samples': 80, 'num_leaves': 77, 'reg_alpha': 0.507867504674038, 'reg_lambda': 0.9233584825228354, 'subsample': 0.9670191838814417, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 94%|█████████▍| 94/100 [2:26:11<08:57, 89.66s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674295\n",
      "[2000]\tvalid_0's auc: 0.676065\n",
      "Early stopping, best iteration is:\n",
      "[2043]\tvalid_0's auc: 0.676099\n",
      "valid scores:\n",
      "[0.6760991114449899]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "96\n",
      "hyper params\n",
      "subsample: 0.9998107343090106 num_leaves: 42.0 subsample_for_bin: 160000.0\n",
      "min_child_samples: 55.0 reg_alpha: 0.3937101881812803 reg_lambda: 0.8830765710302005 colsample_bytree: 0.6540878224428444\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6540878224428444, 'min_child_samples': 55, 'num_leaves': 42, 'reg_alpha': 0.3937101881812803, 'reg_lambda': 0.8830765710302005, 'subsample': 0.9998107343090106, 'subsample_for_bin': 160000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 95%|█████████▌| 95/100 [2:27:44<07:33, 90.69s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.67198\n",
      "[2000]\tvalid_0's auc: 0.674159\n",
      "[3000]\tvalid_0's auc: 0.674838\n",
      "Early stopping, best iteration is:\n",
      "[3127]\tvalid_0's auc: 0.674951\n",
      "valid scores:\n",
      "[0.6749510303715692]\n",
      "CV score: 0.50701 \n",
      "ITERATION:\n",
      "97\n",
      "hyper params\n",
      "subsample: 0.6864696289195185 num_leaves: 80.0 subsample_for_bin: 100000.0\n",
      "min_child_samples: 110.0 reg_alpha: 0.870838541257051 reg_lambda: 0.8019570120016043 colsample_bytree: 0.6387427215983982\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6387427215983982, 'min_child_samples': 110, 'num_leaves': 80, 'reg_alpha': 0.870838541257051, 'reg_lambda': 0.8019570120016043, 'subsample': 0.6864696289195185, 'subsample_for_bin': 100000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 96%|█████████▌| 96/100 [2:29:27<06:17, 94.36s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674795\n",
      "Early stopping, best iteration is:\n",
      "[1606]\tvalid_0's auc: 0.675948\n",
      "valid scores:\n",
      "[0.6759480456180971]\n",
      "CV score: 0.50705 \n",
      "ITERATION:\n",
      "98\n",
      "hyper params\n",
      "subsample: 0.9811541430482679 num_leaves: 72.0 subsample_for_bin: 90000.0\n",
      "min_child_samples: 130.0 reg_alpha: 0.3391245269319102 reg_lambda: 0.9799149966609147 colsample_bytree: 0.6224206597510922\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6224206597510922, 'min_child_samples': 130, 'num_leaves': 72, 'reg_alpha': 0.3391245269319102, 'reg_lambda': 0.9799149966609147, 'subsample': 0.9811541430482679, 'subsample_for_bin': 90000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 97%|█████████▋| 97/100 [2:30:40<04:23, 87.84s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.674818\n",
      "[2000]\tvalid_0's auc: 0.676567\n",
      "Early stopping, best iteration is:\n",
      "[2109]\tvalid_0's auc: 0.676634\n",
      "valid scores:\n",
      "[0.6766341341065009]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "99\n",
      "hyper params\n",
      "subsample: 0.8882938634360983 num_leaves: 70.0 subsample_for_bin: 80000.0\n",
      "min_child_samples: 230.0 reg_alpha: 0.21598429493362925 reg_lambda: 0.9076216970958334 colsample_bytree: 0.6099278789026381\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6099278789026381, 'min_child_samples': 230, 'num_leaves': 70, 'reg_alpha': 0.21598429493362925, 'reg_lambda': 0.9076216970958334, 'subsample': 0.8882938634360983, 'subsample_for_bin': 80000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 98%|█████████▊| 98/100 [2:32:12<02:58, 89.10s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.675153\n",
      "[2000]\tvalid_0's auc: 0.67624\n",
      "Early stopping, best iteration is:\n",
      "[1715]\tvalid_0's auc: 0.676473\n",
      "valid scores:\n",
      "[0.6764728404702253]\n",
      "CV score: 0.50707 \n",
      "ITERATION:\n",
      "100\n",
      "hyper params\n",
      "subsample: 0.9067310847255 num_leaves: 78.0 subsample_for_bin: 150000.0\n",
      "min_child_samples: 160.0 reg_alpha: 0.3174977999459879 reg_lambda: 0.7459424525684414 colsample_bytree: 0.6317729043020681\n",
      "fold n°0\n",
      "param:\n",
      "{'colsample_bytree': 0.6317729043020681, 'min_child_samples': 160, 'num_leaves': 78, 'reg_alpha': 0.3174977999459879, 'reg_lambda': 0.7459424525684414, 'subsample': 0.9067310847255, 'subsample_for_bin': 150000, 'learning_rate': 0.01, 'boosting': 'gbdt', 'bagging_seed': 2018, 'bagging_freq': 2, 'min_data_in_bin': 100, 'n_estimators': 10000, 'objective': 'binary', 'metric': 'auc', 'random_state': 2333, 'max_depth': 15, 'scale_pos_weight': 1}\n",
      " 99%|█████████▉| 99/100 [2:33:32<01:26, 86.46s/it, best loss: 0.4929067119721624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\tvalid_0's auc: 0.6748\n",
      "[2000]\tvalid_0's auc: 0.676289\n",
      "Early stopping, best iteration is:\n",
      "[1701]\tvalid_0's auc: 0.67637\n",
      "valid scores:\n",
      "[0.6763703810898282]\n",
      "CV score: 0.50706 \n",
      "100%|██████████| 100/100 [2:34:54<00:00, 85.21s/it, best loss: 0.4929067119721624]\n",
      "CPU times: user 9h 52min 51s, sys: 14min 20s, total: 10h 7min 11s\n",
      "Wall time: 2h 34min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "MAX_EVALS = 200+100\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "123e5f284af6c86da7dad07021788f27d92b1309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.4929067119721624,\n",
       "  'hyperparameters': {'colsample_bytree': 0.6070263484848221,\n",
       "   'min_child_samples': 120,\n",
       "   'num_leaves': 65,\n",
       "   'reg_alpha': 0.4086395992151187,\n",
       "   'reg_lambda': 0.8723592642214507,\n",
       "   'subsample': 0.9764323431114542,\n",
       "   'subsample_for_bin': 160000,\n",
       "   'learning_rate': 0.01,\n",
       "   'boosting': 'gbdt',\n",
       "   'bagging_seed': 2018,\n",
       "   'bagging_freq': 2,\n",
       "   'min_data_in_bin': 100,\n",
       "   'n_estimators': [2377],\n",
       "   'objective': 'binary',\n",
       "   'metric': 'auc',\n",
       "   'random_state': 2333,\n",
       "   'max_depth': 15,\n",
       "   'scale_pos_weight': 1},\n",
       "  'iteration': 78,\n",
       "  'train_time': 97.4711585569894,\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the trials with lowest loss first\n",
    "trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n",
    "trials_dict[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "fcc07d6c35f2f3ae659708f1061fea91e5ef44ab"
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "0318d2b57cb6248c855508b2def24180b064a21b"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pickle.dump(trials, open(\"trials_cls.pickle\", \"wb\"))\n",
    "# Save the trial results\n",
    "# with open('trials.json', 'w') as f:\n",
    "#     f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "d3ebc29f92baec07f036b79a203a67e54371cfb8"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def evaluate(results, name,train_df,y_reg):\n",
    "    \"\"\"Evaluate model on test data using hyperparameters in results\n",
    "       Return dataframe of hyperparameters\"\"\"\n",
    "    \n",
    "    new_results = results.copy()\n",
    "    # String to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "    \n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    \n",
    "    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n",
    "\n",
    "    # Iterate through each set of hyperparameters that were evaluated\n",
    "    for i, hyp in enumerate(new_results['hyperparameters']):\n",
    "        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = new_results['iteration']\n",
    "    hyp_df['score'] = new_results['score']\n",
    "    hyp_df['valid_scores'] = new_results['valid_scores']\n",
    "    \n",
    "    return hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "2c5818783dab1336a30a4e9cb67d35312e7538f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from Bayesian was 0.50709 found on iteration 73.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>boosting</th>\n",
       "      <th>bagging_seed</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>min_data_in_bin</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>objective</th>\n",
       "      <th>metric</th>\n",
       "      <th>random_state</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "      <th>valid_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641797</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>0.994722</td>\n",
       "      <td>0.940123</td>\n",
       "      <td>0.981634</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2526</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0.507089</td>\n",
       "      <td>[0.677042755384619]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607925</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "      <td>0.300099</td>\n",
       "      <td>0.949717</td>\n",
       "      <td>0.983533</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2175</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0.507080</td>\n",
       "      <td>[0.6768204493478739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621359</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>0.307295</td>\n",
       "      <td>0.793069</td>\n",
       "      <td>0.953702</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2054</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.507080</td>\n",
       "      <td>[0.6768030742478867]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.626301</td>\n",
       "      <td>140</td>\n",
       "      <td>76</td>\n",
       "      <td>0.252713</td>\n",
       "      <td>0.903210</td>\n",
       "      <td>0.990027</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1979</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.507079</td>\n",
       "      <td>[0.6767994268703607]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657893</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>0.990661</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.945740</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2486</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.507078</td>\n",
       "      <td>[0.6767729035630919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.643208</td>\n",
       "      <td>230</td>\n",
       "      <td>61</td>\n",
       "      <td>0.304983</td>\n",
       "      <td>0.779514</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2240</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.507078</td>\n",
       "      <td>[0.6767535532512398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.632566</td>\n",
       "      <td>130</td>\n",
       "      <td>65</td>\n",
       "      <td>0.482405</td>\n",
       "      <td>0.970312</td>\n",
       "      <td>0.965524</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2261</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.507075</td>\n",
       "      <td>[0.6766967740274316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.600761</td>\n",
       "      <td>200</td>\n",
       "      <td>63</td>\n",
       "      <td>0.514043</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.980713</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2193</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.507074</td>\n",
       "      <td>[0.6766657442607642]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.622421</td>\n",
       "      <td>130</td>\n",
       "      <td>72</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.979915</td>\n",
       "      <td>0.981154</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2109</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.507073</td>\n",
       "      <td>[0.6766341341065009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600749</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>0.945721</td>\n",
       "      <td>0.955755</td>\n",
       "      <td>0.931900</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2188</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>0.507070</td>\n",
       "      <td>[0.676570176475737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.601701</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.270160</td>\n",
       "      <td>0.825134</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2148</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.507070</td>\n",
       "      <td>[0.6765674734118287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.662757</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>0.225720</td>\n",
       "      <td>0.754539</td>\n",
       "      <td>0.971115</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2702</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0.507070</td>\n",
       "      <td>[0.6765605574645317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.653908</td>\n",
       "      <td>55</td>\n",
       "      <td>79</td>\n",
       "      <td>0.955370</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2395</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.507068</td>\n",
       "      <td>[0.6765137138269812]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.711517</td>\n",
       "      <td>170</td>\n",
       "      <td>71</td>\n",
       "      <td>0.577651</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.974838</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1843</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.507068</td>\n",
       "      <td>[0.6765061336132282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.699264</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>0.903811</td>\n",
       "      <td>0.847432</td>\n",
       "      <td>0.933783</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2185</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>[0.6764748955022957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.637549</td>\n",
       "      <td>195</td>\n",
       "      <td>53</td>\n",
       "      <td>0.480771</td>\n",
       "      <td>0.851373</td>\n",
       "      <td>0.900863</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2329</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>[0.6764736346136258]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.609928</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>0.215984</td>\n",
       "      <td>0.907622</td>\n",
       "      <td>0.888294</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1715</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>[0.6764728404702253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.647446</td>\n",
       "      <td>150</td>\n",
       "      <td>78</td>\n",
       "      <td>0.367171</td>\n",
       "      <td>0.794712</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1758</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0.507063</td>\n",
       "      <td>[0.6763938834052513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.631773</td>\n",
       "      <td>160</td>\n",
       "      <td>78</td>\n",
       "      <td>0.317498</td>\n",
       "      <td>0.745942</td>\n",
       "      <td>0.906731</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1701</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.507062</td>\n",
       "      <td>[0.6763703810898282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.629347</td>\n",
       "      <td>85</td>\n",
       "      <td>54</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.109049</td>\n",
       "      <td>0.982474</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>3320</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.507062</td>\n",
       "      <td>[0.6763596188909339]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.626129</td>\n",
       "      <td>165</td>\n",
       "      <td>68</td>\n",
       "      <td>0.372286</td>\n",
       "      <td>0.871650</td>\n",
       "      <td>0.804134</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1874</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.507062</td>\n",
       "      <td>[0.6763549771430513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.615670</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>0.182122</td>\n",
       "      <td>0.760191</td>\n",
       "      <td>0.952255</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2090</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.507061</td>\n",
       "      <td>[0.67634347491615]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.684946</td>\n",
       "      <td>135</td>\n",
       "      <td>64</td>\n",
       "      <td>0.223706</td>\n",
       "      <td>0.860525</td>\n",
       "      <td>0.874487</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2237</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.507061</td>\n",
       "      <td>[0.6763330008817264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.618657</td>\n",
       "      <td>115</td>\n",
       "      <td>66</td>\n",
       "      <td>0.353777</td>\n",
       "      <td>0.787458</td>\n",
       "      <td>0.970925</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2450</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.507060</td>\n",
       "      <td>[0.6763108744501846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.761193</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.253323</td>\n",
       "      <td>0.917038</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1831</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.507059</td>\n",
       "      <td>[0.6763012256755128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.673856</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>0.918693</td>\n",
       "      <td>0.897219</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2219</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0.507059</td>\n",
       "      <td>[0.6762925509779251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.614596</td>\n",
       "      <td>125</td>\n",
       "      <td>76</td>\n",
       "      <td>0.466634</td>\n",
       "      <td>0.863783</td>\n",
       "      <td>0.913213</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1688</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0.507059</td>\n",
       "      <td>[0.6762832607177357]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.649229</td>\n",
       "      <td>175</td>\n",
       "      <td>73</td>\n",
       "      <td>0.490315</td>\n",
       "      <td>0.836903</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2226</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.507059</td>\n",
       "      <td>[0.6762793941728658]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.645042</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>0.553760</td>\n",
       "      <td>0.727792</td>\n",
       "      <td>0.965490</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2258</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0.507058</td>\n",
       "      <td>[0.6762690297221142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.653325</td>\n",
       "      <td>185</td>\n",
       "      <td>62</td>\n",
       "      <td>0.458132</td>\n",
       "      <td>0.774751</td>\n",
       "      <td>0.948197</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2256</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0.507058</td>\n",
       "      <td>[0.6762583771068919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.633592</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.338794</td>\n",
       "      <td>0.916506</td>\n",
       "      <td>0.919631</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2054</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.507057</td>\n",
       "      <td>[0.6762388157450047]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.600329</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>0.733246</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.882173</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2005</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.507057</td>\n",
       "      <td>[0.6762374953294018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.645091</td>\n",
       "      <td>115</td>\n",
       "      <td>64</td>\n",
       "      <td>0.467116</td>\n",
       "      <td>0.801213</td>\n",
       "      <td>0.988457</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2765</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507057</td>\n",
       "      <td>[0.6762289505087588]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.627764</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.836897</td>\n",
       "      <td>0.969440</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2443</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507056</td>\n",
       "      <td>[0.6762123357300509]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.797366</td>\n",
       "      <td>245</td>\n",
       "      <td>76</td>\n",
       "      <td>0.796501</td>\n",
       "      <td>0.770059</td>\n",
       "      <td>0.927669</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1940</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.507056</td>\n",
       "      <td>[0.6762109003192367]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.608934</td>\n",
       "      <td>175</td>\n",
       "      <td>58</td>\n",
       "      <td>0.426127</td>\n",
       "      <td>0.939637</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2180</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.507056</td>\n",
       "      <td>[0.6762062775117419]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.639493</td>\n",
       "      <td>105</td>\n",
       "      <td>57</td>\n",
       "      <td>0.293799</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>0.943899</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2526</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.507056</td>\n",
       "      <td>[0.6762037909094077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.735556</td>\n",
       "      <td>240</td>\n",
       "      <td>73</td>\n",
       "      <td>0.500190</td>\n",
       "      <td>0.900285</td>\n",
       "      <td>0.860953</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1667</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.507055</td>\n",
       "      <td>[0.6761843567186955]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.815295</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>0.558443</td>\n",
       "      <td>0.814631</td>\n",
       "      <td>0.913622</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2025</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.507054</td>\n",
       "      <td>[0.676159201177999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.666972</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.030587</td>\n",
       "      <td>0.947049</td>\n",
       "      <td>0.961003</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2380</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.507053</td>\n",
       "      <td>[0.6761391852468059]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.660746</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>0.318465</td>\n",
       "      <td>0.980880</td>\n",
       "      <td>0.893352</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1687</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.507052</td>\n",
       "      <td>[0.6761251111858259]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.601588</td>\n",
       "      <td>190</td>\n",
       "      <td>59</td>\n",
       "      <td>0.349332</td>\n",
       "      <td>0.910104</td>\n",
       "      <td>0.852092</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2228</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.507051</td>\n",
       "      <td>[0.6760993630815699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.702170</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>0.507868</td>\n",
       "      <td>0.923358</td>\n",
       "      <td>0.967019</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2043</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.507051</td>\n",
       "      <td>[0.6760991114449899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.616715</td>\n",
       "      <td>135</td>\n",
       "      <td>78</td>\n",
       "      <td>0.270230</td>\n",
       "      <td>0.857072</td>\n",
       "      <td>0.984362</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1831</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.507051</td>\n",
       "      <td>[0.6760862549803648]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.670183</td>\n",
       "      <td>90</td>\n",
       "      <td>73</td>\n",
       "      <td>0.315398</td>\n",
       "      <td>0.708516</td>\n",
       "      <td>0.956966</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2191</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0.507050</td>\n",
       "      <td>[0.6760679274494509]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.701588</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>0.634009</td>\n",
       "      <td>0.932144</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2185</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.507050</td>\n",
       "      <td>[0.6760655328432857]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.722730</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.926137</td>\n",
       "      <td>0.938621</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2584</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.507050</td>\n",
       "      <td>[0.6760652325028516]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.682163</td>\n",
       "      <td>35</td>\n",
       "      <td>72</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.741403</td>\n",
       "      <td>0.909302</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2626</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.507050</td>\n",
       "      <td>[0.6760612671973885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.624057</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>0.899707</td>\n",
       "      <td>0.972581</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2068</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.507049</td>\n",
       "      <td>[0.6760437662791111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.831184</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.932123</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2600</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.507048</td>\n",
       "      <td>[0.6760022354203233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.668260</td>\n",
       "      <td>125</td>\n",
       "      <td>68</td>\n",
       "      <td>0.434723</td>\n",
       "      <td>0.982885</td>\n",
       "      <td>0.923692</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2227</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0.507047</td>\n",
       "      <td>[0.6759908373655548]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.620643</td>\n",
       "      <td>130</td>\n",
       "      <td>78</td>\n",
       "      <td>0.468301</td>\n",
       "      <td>0.738615</td>\n",
       "      <td>0.986572</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1785</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.507047</td>\n",
       "      <td>[0.6759820828477615]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.674716</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>0.241627</td>\n",
       "      <td>0.752936</td>\n",
       "      <td>0.938633</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2375</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.507046</td>\n",
       "      <td>[0.6759699095899802]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.681363</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "      <td>0.919694</td>\n",
       "      <td>0.879381</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2621</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0.507046</td>\n",
       "      <td>[0.675954095719097]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.638743</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0.870839</td>\n",
       "      <td>0.801957</td>\n",
       "      <td>0.686470</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1606</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.507045</td>\n",
       "      <td>[0.6759480456180971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.657243</td>\n",
       "      <td>185</td>\n",
       "      <td>68</td>\n",
       "      <td>0.335497</td>\n",
       "      <td>0.609997</td>\n",
       "      <td>0.821452</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1855</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.507045</td>\n",
       "      <td>[0.6759387945915679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.600035</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.353049</td>\n",
       "      <td>0.890687</td>\n",
       "      <td>0.956589</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>4133</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0.507043</td>\n",
       "      <td>[0.6758797817548906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.641561</td>\n",
       "      <td>95</td>\n",
       "      <td>79</td>\n",
       "      <td>0.086588</td>\n",
       "      <td>0.809666</td>\n",
       "      <td>0.958263</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2237</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>[0.6758577270262451]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.607626</td>\n",
       "      <td>165</td>\n",
       "      <td>66</td>\n",
       "      <td>0.440728</td>\n",
       "      <td>0.883941</td>\n",
       "      <td>0.977856</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2223</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>[0.6758463600878278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.664647</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>0.376732</td>\n",
       "      <td>0.998523</td>\n",
       "      <td>0.734706</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1694</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>[0.6758299428303066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.629987</td>\n",
       "      <td>40</td>\n",
       "      <td>79</td>\n",
       "      <td>0.753430</td>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.991224</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2250</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>[0.6758264523874219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.776479</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>0.707884</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.976597</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1826</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>[0.6758246909313615]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.689033</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.817301</td>\n",
       "      <td>0.720340</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1920</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>[0.6758194620314588]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.734286</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>0.441769</td>\n",
       "      <td>0.671668</td>\n",
       "      <td>0.939813</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2418</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>[0.6758132982881323]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.615064</td>\n",
       "      <td>125</td>\n",
       "      <td>77</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.922789</td>\n",
       "      <td>0.987761</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1608</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.507039</td>\n",
       "      <td>[0.67579226769331]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.743090</td>\n",
       "      <td>220</td>\n",
       "      <td>69</td>\n",
       "      <td>0.168703</td>\n",
       "      <td>0.721224</td>\n",
       "      <td>0.955806</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1780</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.507039</td>\n",
       "      <td>[0.6757776849476304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.770843</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>0.380855</td>\n",
       "      <td>0.813439</td>\n",
       "      <td>0.909468</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2130</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.507038</td>\n",
       "      <td>[0.6757611148141223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.625979</td>\n",
       "      <td>105</td>\n",
       "      <td>77</td>\n",
       "      <td>0.362181</td>\n",
       "      <td>0.791912</td>\n",
       "      <td>0.760461</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1608</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.507038</td>\n",
       "      <td>[0.6757571779192407]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.677926</td>\n",
       "      <td>95</td>\n",
       "      <td>74</td>\n",
       "      <td>0.290227</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.932439</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2014</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.507037</td>\n",
       "      <td>[0.6757320656708592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.784391</td>\n",
       "      <td>140</td>\n",
       "      <td>33</td>\n",
       "      <td>0.670678</td>\n",
       "      <td>0.693704</td>\n",
       "      <td>0.965757</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>3510</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.507037</td>\n",
       "      <td>[0.6757283993529455]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.692812</td>\n",
       "      <td>145</td>\n",
       "      <td>31</td>\n",
       "      <td>0.570627</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>0.844214</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>3697</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.507036</td>\n",
       "      <td>[0.6757052163183443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.707423</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>0.534657</td>\n",
       "      <td>0.959170</td>\n",
       "      <td>0.778473</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1771</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>[0.6756947517541146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.650638</td>\n",
       "      <td>65</td>\n",
       "      <td>79</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.716079</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1838</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>[0.6756938777905086]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.754114</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>0.604123</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.892801</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2482</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>[0.6756911584919822]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.633802</td>\n",
       "      <td>110</td>\n",
       "      <td>51</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>0.997335</td>\n",
       "      <td>0.667894</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2409</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>[0.6756882998463174]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.606834</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "      <td>0.147264</td>\n",
       "      <td>0.980176</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2065</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>[0.6756870213701446]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.883009</td>\n",
       "      <td>150</td>\n",
       "      <td>47</td>\n",
       "      <td>0.410023</td>\n",
       "      <td>0.686122</td>\n",
       "      <td>0.940029</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2626</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.507033</td>\n",
       "      <td>[0.6756454323373088]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.616747</td>\n",
       "      <td>35</td>\n",
       "      <td>74</td>\n",
       "      <td>0.112632</td>\n",
       "      <td>0.637297</td>\n",
       "      <td>0.971052</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2028</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.507033</td>\n",
       "      <td>[0.6756384744505818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.727998</td>\n",
       "      <td>210</td>\n",
       "      <td>75</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>0.937823</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1894</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.507033</td>\n",
       "      <td>[0.6756276594891788]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.611919</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>0.183441</td>\n",
       "      <td>0.823657</td>\n",
       "      <td>0.938717</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1624</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.507031</td>\n",
       "      <td>[0.6755842413560407]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.863148</td>\n",
       "      <td>120</td>\n",
       "      <td>78</td>\n",
       "      <td>0.280545</td>\n",
       "      <td>0.801603</td>\n",
       "      <td>0.884449</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2221</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.507029</td>\n",
       "      <td>[0.6755432611213824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.718670</td>\n",
       "      <td>285</td>\n",
       "      <td>63</td>\n",
       "      <td>0.391444</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.950772</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1967</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>[0.6755260646021938]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.659968</td>\n",
       "      <td>110</td>\n",
       "      <td>27</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.850638</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>4067</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>[0.6755177240671614]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.690789</td>\n",
       "      <td>140</td>\n",
       "      <td>68</td>\n",
       "      <td>0.263586</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>0.745786</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1462</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>[0.6755150818830707]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.609285</td>\n",
       "      <td>175</td>\n",
       "      <td>63</td>\n",
       "      <td>0.204875</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1986</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>[0.6755030872060882]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.874506</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>0.428518</td>\n",
       "      <td>0.663898</td>\n",
       "      <td>0.793737</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2579</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.507023</td>\n",
       "      <td>[0.6753942868544507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.833294</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>0.525174</td>\n",
       "      <td>0.960785</td>\n",
       "      <td>0.655920</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2148</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.507022</td>\n",
       "      <td>[0.6753556579336426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.940268</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>0.621829</td>\n",
       "      <td>0.940946</td>\n",
       "      <td>0.949739</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2357</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0.507019</td>\n",
       "      <td>[0.67529937792434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.692040</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>0.647634</td>\n",
       "      <td>0.971860</td>\n",
       "      <td>0.616270</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2507</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.507018</td>\n",
       "      <td>[0.6752548734246762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.847677</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>0.545067</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>0.947625</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>4734</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.507018</td>\n",
       "      <td>[0.6752529482695503]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.642110</td>\n",
       "      <td>30</td>\n",
       "      <td>77</td>\n",
       "      <td>0.849380</td>\n",
       "      <td>0.966130</td>\n",
       "      <td>0.992643</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2016</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0.507017</td>\n",
       "      <td>[0.6752444616229553]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.960941</td>\n",
       "      <td>155</td>\n",
       "      <td>80</td>\n",
       "      <td>0.318991</td>\n",
       "      <td>0.159282</td>\n",
       "      <td>0.903068</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1663</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.507016</td>\n",
       "      <td>[0.6752090444507549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.635462</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "      <td>0.395222</td>\n",
       "      <td>0.954632</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2736</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>[0.67519038952171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.648274</td>\n",
       "      <td>105</td>\n",
       "      <td>67</td>\n",
       "      <td>0.411877</td>\n",
       "      <td>0.828185</td>\n",
       "      <td>0.703590</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1666</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.507010</td>\n",
       "      <td>[0.6750586320672394]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.985856</td>\n",
       "      <td>260</td>\n",
       "      <td>71</td>\n",
       "      <td>0.588803</td>\n",
       "      <td>0.871126</td>\n",
       "      <td>0.865994</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.507010</td>\n",
       "      <td>[0.6750580002700196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.600039</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>0.412768</td>\n",
       "      <td>0.838689</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1713</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.507008</td>\n",
       "      <td>[0.6750179102335854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.654088</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>0.393710</td>\n",
       "      <td>0.883077</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>3127</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>[0.6749510303715692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.711325</td>\n",
       "      <td>145</td>\n",
       "      <td>20</td>\n",
       "      <td>0.432937</td>\n",
       "      <td>0.895620</td>\n",
       "      <td>0.963848</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>5232</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.507004</td>\n",
       "      <td>[0.6749228105467124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.927356</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>0.380216</td>\n",
       "      <td>0.133093</td>\n",
       "      <td>0.991539</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1951</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.506976</td>\n",
       "      <td>[0.6742160405077748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.911505</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>0.413457</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>0.982537</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2220</td>\n",
       "      <td>binary</td>\n",
       "      <td>auc</td>\n",
       "      <td>2333</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.506961</td>\n",
       "      <td>[0.6738403470937532]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree min_child_samples num_leaves  reg_alpha  reg_lambda  \\\n",
       "0           0.641797                60         76   0.994722    0.940123   \n",
       "1           0.607925               115         75   0.300099    0.949717   \n",
       "2           0.621359               150         73   0.307295    0.793069   \n",
       "3           0.626301               140         76   0.252713    0.903210   \n",
       "4           0.657893                45         67   0.990661    0.999136   \n",
       "5           0.643208               230         61   0.304983    0.779514   \n",
       "6           0.632566               130         65   0.482405    0.970312   \n",
       "7           0.600761               200         63   0.514043    0.861794   \n",
       "8           0.622421               130         72   0.339125    0.979915   \n",
       "9           0.600749                30         74   0.945721    0.955755   \n",
       "10          0.601701                80         70   0.270160    0.825134   \n",
       "11          0.662757               100         69   0.225720    0.754539   \n",
       "12          0.653908                55         79   0.955370    0.932000   \n",
       "13          0.711517               170         71   0.577651    0.999795   \n",
       "14          0.699264                75         77   0.903811    0.847432   \n",
       "15          0.637549               195         53   0.480771    0.851373   \n",
       "16          0.609928               230         70   0.215984    0.907622   \n",
       "17          0.647446               150         78   0.367171    0.794712   \n",
       "18          0.631773               160         78   0.317498    0.745942   \n",
       "19          0.629347                85         54   0.453665    0.109049   \n",
       "20          0.626129               165         68   0.372286    0.871650   \n",
       "21          0.615670                80         62   0.182122    0.760191   \n",
       "22          0.684946               135         64   0.223706    0.860525   \n",
       "23          0.618657               115         66   0.353777    0.787458   \n",
       "24          0.761193               120         80   0.253323    0.917038   \n",
       "25          0.673856                35         80   0.496053    0.918693   \n",
       "26          0.614596               125         76   0.466634    0.863783   \n",
       "27          0.649229               175         73   0.490315    0.836903   \n",
       "28          0.645042                90         70   0.553760    0.727792   \n",
       "29          0.653325               185         62   0.458132    0.774751   \n",
       "30          0.633592                80         80   0.338794    0.916506   \n",
       "31          0.600329               205         65   0.733246    0.999912   \n",
       "32          0.645091               115         64   0.467116    0.801213   \n",
       "33          0.627764                45         76   0.288071    0.836897   \n",
       "34          0.797366               245         76   0.796501    0.770059   \n",
       "35          0.608934               175         58   0.426127    0.939637   \n",
       "36          0.639493               105         57   0.293799    0.877737   \n",
       "37          0.735556               240         73   0.500190    0.900285   \n",
       "38          0.815295                90         72   0.558443    0.814631   \n",
       "39          0.666972                80         60   0.030587    0.947049   \n",
       "40          0.660746                75         72   0.318465    0.980880   \n",
       "41          0.601588               190         59   0.349332    0.910104   \n",
       "42          0.702170                80         77   0.507868    0.923358   \n",
       "43          0.616715               135         78   0.270230    0.857072   \n",
       "44          0.670183                90         73   0.315398    0.708516   \n",
       "45          0.701588                40         75   0.634009    0.932144   \n",
       "46          0.722730               125         55   0.136993    0.926137   \n",
       "47          0.682163                35         72   0.335300    0.741403   \n",
       "48          0.624057                85         76   0.460726    0.899707   \n",
       "49          0.831184                50         52   0.400242    0.899416   \n",
       "50          0.668260               125         68   0.434723    0.982885   \n",
       "51          0.620643               130         78   0.468301    0.738615   \n",
       "52          0.674716                60         71   0.241627    0.752936   \n",
       "53          0.681363                65         71   0.919694    0.879381   \n",
       "54          0.638743               110         80   0.870839    0.801957   \n",
       "55          0.657243               185         68   0.335497    0.609997   \n",
       "56          0.600035                60         36   0.353049    0.890687   \n",
       "57          0.641561                95         79   0.086588    0.809666   \n",
       "58          0.607626               165         66   0.440728    0.883941   \n",
       "59          0.664647               100         74   0.376732    0.998523   \n",
       "60          0.629987                40         79   0.753430    0.767939   \n",
       "61          0.776479               270         61   0.707884    0.529770   \n",
       "62          0.689033                50         73   0.536960    0.817301   \n",
       "63          0.734286                95         64   0.441769    0.671668   \n",
       "64          0.615064               125         77   0.002991    0.922789   \n",
       "65          0.743090               220         69   0.168703    0.721224   \n",
       "66          0.770843               160         70   0.380855    0.813439   \n",
       "67          0.625979               105         77   0.362181    0.791912   \n",
       "68          0.677926                95         74   0.290227    0.836421   \n",
       "69          0.784391               140         33   0.670678    0.693704   \n",
       "70          0.692812               145         31   0.570627    0.998862   \n",
       "71          0.707423               100         67   0.534657    0.959170   \n",
       "72          0.650638                65         79   0.232797    0.716079   \n",
       "73          0.754114                45         65   0.604123    0.892157   \n",
       "74          0.633802               110         51   0.508065    0.997335   \n",
       "75          0.606834               115         75   0.147264    0.980176   \n",
       "76          0.883009               150         47   0.410023    0.686122   \n",
       "77          0.616747                35         74   0.112632    0.637297   \n",
       "78          0.727998               210         75   0.054497    0.937823   \n",
       "79          0.611919                70         74   0.183441    0.823657   \n",
       "80          0.863148               120         78   0.280545    0.801603   \n",
       "81          0.718670               285         63   0.391444    0.989781   \n",
       "82          0.659968               110         27   0.200021    0.850638   \n",
       "83          0.690789               140         68   0.263586    0.876887   \n",
       "84          0.609285               175         63   0.204875    0.650995   \n",
       "85          0.874506                70         45   0.428518    0.663898   \n",
       "86          0.833294                55         57   0.525174    0.960785   \n",
       "87          0.940268                70         69   0.621829    0.940946   \n",
       "88          0.692040                65         56   0.647634    0.971860   \n",
       "89          0.847677               100         23   0.545067    0.950208   \n",
       "90          0.642110                30         77   0.849380    0.966130   \n",
       "91          0.960941               155         80   0.318991    0.159282   \n",
       "92          0.635462                60         72   0.395222    0.954632   \n",
       "93          0.648274               105         67   0.411877    0.828185   \n",
       "94          0.985856               260         71   0.588803    0.871126   \n",
       "95          0.600039               160         60   0.412768    0.838689   \n",
       "96          0.654088                55         42   0.393710    0.883077   \n",
       "97          0.711325               145         20   0.432937    0.895620   \n",
       "98          0.927356                50         70   0.380216    0.133093   \n",
       "99          0.911505                30         66   0.413457    0.062680   \n",
       "\n",
       "    subsample subsample_for_bin  learning_rate boosting bagging_seed  \\\n",
       "0    0.981634            160000           0.01     gbdt         2018   \n",
       "1    0.983533            160000           0.01     gbdt         2018   \n",
       "2    0.953702            160000           0.01     gbdt         2018   \n",
       "3    0.990027            160000           0.01     gbdt         2018   \n",
       "4    0.945740            160000           0.01     gbdt         2018   \n",
       "5    0.945783            160000           0.01     gbdt         2018   \n",
       "6    0.965524            160000           0.01     gbdt         2018   \n",
       "7    0.980713            160000           0.01     gbdt         2018   \n",
       "8    0.981154             90000           0.01     gbdt         2018   \n",
       "9    0.931900            160000           0.01     gbdt         2018   \n",
       "10   0.991587            160000           0.01     gbdt         2018   \n",
       "11   0.971115            160000           0.01     gbdt         2018   \n",
       "12   0.961385            160000           0.01     gbdt         2018   \n",
       "13   0.974838            160000           0.01     gbdt         2018   \n",
       "14   0.933783            160000           0.01     gbdt         2018   \n",
       "15   0.900863             90000           0.01     gbdt         2018   \n",
       "16   0.888294             80000           0.01     gbdt         2018   \n",
       "17   0.998920            160000           0.01     gbdt         2018   \n",
       "18   0.906731            150000           0.01     gbdt         2018   \n",
       "19   0.982474            160000           0.01     gbdt         2018   \n",
       "20   0.804134             80000           0.01     gbdt         2018   \n",
       "21   0.952255            130000           0.01     gbdt         2018   \n",
       "22   0.874487            100000           0.01     gbdt         2018   \n",
       "23   0.970925            160000           0.01     gbdt         2018   \n",
       "24   0.973520            160000           0.01     gbdt         2018   \n",
       "25   0.897219            160000           0.01     gbdt         2018   \n",
       "26   0.913213            150000           0.01     gbdt         2018   \n",
       "27   0.918187            100000           0.01     gbdt         2018   \n",
       "28   0.965490            160000           0.01     gbdt         2018   \n",
       "29   0.948197            110000           0.01     gbdt         2018   \n",
       "30   0.919631            150000           0.01     gbdt         2018   \n",
       "31   0.882173            150000           0.01     gbdt         2018   \n",
       "32   0.988457            140000           0.01     gbdt         2018   \n",
       "33   0.969440            110000           0.01     gbdt         2018   \n",
       "34   0.927669            150000           0.01     gbdt         2018   \n",
       "35   0.999101            160000           0.01     gbdt         2018   \n",
       "36   0.943899            160000           0.01     gbdt         2018   \n",
       "37   0.860953            140000           0.01     gbdt         2018   \n",
       "38   0.913622            160000           0.01     gbdt         2018   \n",
       "39   0.961003            110000           0.01     gbdt         2018   \n",
       "40   0.893352            130000           0.01     gbdt         2018   \n",
       "41   0.852092            140000           0.01     gbdt         2018   \n",
       "42   0.967019            150000           0.01     gbdt         2018   \n",
       "43   0.984362            150000           0.01     gbdt         2018   \n",
       "44   0.956966            150000           0.01     gbdt         2018   \n",
       "45   0.921714            160000           0.01     gbdt         2018   \n",
       "46   0.938621             80000           0.01     gbdt         2018   \n",
       "47   0.909302            150000           0.01     gbdt         2018   \n",
       "48   0.972581            150000           0.01     gbdt         2018   \n",
       "49   0.932123            120000           0.01     gbdt         2018   \n",
       "50   0.923692            150000           0.01     gbdt         2018   \n",
       "51   0.986572            140000           0.01     gbdt         2018   \n",
       "52   0.938633            160000           0.01     gbdt         2018   \n",
       "53   0.979061            150000           0.01     gbdt         2018   \n",
       "54   0.686470            100000           0.01     gbdt         2018   \n",
       "55   0.821452             80000           0.01     gbdt         2018   \n",
       "56   0.956589            160000           0.01     gbdt         2018   \n",
       "57   0.958263            140000           0.01     gbdt         2018   \n",
       "58   0.977856            120000           0.01     gbdt         2018   \n",
       "59   0.734706            160000           0.01     gbdt         2018   \n",
       "60   0.991224            150000           0.01     gbdt         2018   \n",
       "61   0.976597             90000           0.01     gbdt         2018   \n",
       "62   0.720340            160000           0.01     gbdt         2018   \n",
       "63   0.939813            100000           0.01     gbdt         2018   \n",
       "64   0.987761            130000           0.01     gbdt         2018   \n",
       "65   0.955806            120000           0.01     gbdt         2018   \n",
       "66   0.909468            140000           0.01     gbdt         2018   \n",
       "67   0.760461            140000           0.01     gbdt         2018   \n",
       "68   0.932439            150000           0.01     gbdt         2018   \n",
       "69   0.965757            140000           0.01     gbdt         2018   \n",
       "70   0.844214            160000           0.01     gbdt         2018   \n",
       "71   0.778473            160000           0.01     gbdt         2018   \n",
       "72   0.995536            160000           0.01     gbdt         2018   \n",
       "73   0.892801            150000           0.01     gbdt         2018   \n",
       "74   0.667894            130000           0.01     gbdt         2018   \n",
       "75   0.999551            150000           0.01     gbdt         2018   \n",
       "76   0.940029            150000           0.01     gbdt         2018   \n",
       "77   0.971052            130000           0.01     gbdt         2018   \n",
       "78   0.999232             90000           0.01     gbdt         2018   \n",
       "79   0.938717            150000           0.01     gbdt         2018   \n",
       "80   0.884449            110000           0.01     gbdt         2018   \n",
       "81   0.950772            150000           0.01     gbdt         2018   \n",
       "82   0.926344            160000           0.01     gbdt         2018   \n",
       "83   0.745786            120000           0.01     gbdt         2018   \n",
       "84   0.999833            110000           0.01     gbdt         2018   \n",
       "85   0.793737            150000           0.01     gbdt         2018   \n",
       "86   0.655920            100000           0.01     gbdt         2018   \n",
       "87   0.949739            140000           0.01     gbdt         2018   \n",
       "88   0.616270            160000           0.01     gbdt         2018   \n",
       "89   0.947625            100000           0.01     gbdt         2018   \n",
       "90   0.992643            150000           0.01     gbdt         2018   \n",
       "91   0.903068             80000           0.01     gbdt         2018   \n",
       "92   0.999893            140000           0.01     gbdt         2018   \n",
       "93   0.703590            140000           0.01     gbdt         2018   \n",
       "94   0.865994             90000           0.01     gbdt         2018   \n",
       "95   0.636720            150000           0.01     gbdt         2018   \n",
       "96   0.999811            160000           0.01     gbdt         2018   \n",
       "97   0.963848            150000           0.01     gbdt         2018   \n",
       "98   0.991539            150000           0.01     gbdt         2018   \n",
       "99   0.982537            150000           0.01     gbdt         2018   \n",
       "\n",
       "   bagging_freq min_data_in_bin n_estimators objective metric random_state  \\\n",
       "0             2             100         2526    binary    auc         2333   \n",
       "1             2             100         2175    binary    auc         2333   \n",
       "2             2             100         2054    binary    auc         2333   \n",
       "3             2             100         1979    binary    auc         2333   \n",
       "4             2             100         2486    binary    auc         2333   \n",
       "5             2             100         2240    binary    auc         2333   \n",
       "6             2             100         2261    binary    auc         2333   \n",
       "7             2             100         2193    binary    auc         2333   \n",
       "8             2             100         2109    binary    auc         2333   \n",
       "9             2             100         2188    binary    auc         2333   \n",
       "10            2             100         2148    binary    auc         2333   \n",
       "11            2             100         2702    binary    auc         2333   \n",
       "12            2             100         2395    binary    auc         2333   \n",
       "13            2             100         1843    binary    auc         2333   \n",
       "14            2             100         2185    binary    auc         2333   \n",
       "15            2             100         2329    binary    auc         2333   \n",
       "16            2             100         1715    binary    auc         2333   \n",
       "17            2             100         1758    binary    auc         2333   \n",
       "18            2             100         1701    binary    auc         2333   \n",
       "19            2             100         3320    binary    auc         2333   \n",
       "20            2             100         1874    binary    auc         2333   \n",
       "21            2             100         2090    binary    auc         2333   \n",
       "22            2             100         2237    binary    auc         2333   \n",
       "23            2             100         2450    binary    auc         2333   \n",
       "24            2             100         1831    binary    auc         2333   \n",
       "25            2             100         2219    binary    auc         2333   \n",
       "26            2             100         1688    binary    auc         2333   \n",
       "27            2             100         2226    binary    auc         2333   \n",
       "28            2             100         2258    binary    auc         2333   \n",
       "29            2             100         2256    binary    auc         2333   \n",
       "30            2             100         2054    binary    auc         2333   \n",
       "31            2             100         2005    binary    auc         2333   \n",
       "32            2             100         2765    binary    auc         2333   \n",
       "33            2             100         2443    binary    auc         2333   \n",
       "34            2             100         1940    binary    auc         2333   \n",
       "35            2             100         2180    binary    auc         2333   \n",
       "36            2             100         2526    binary    auc         2333   \n",
       "37            2             100         1667    binary    auc         2333   \n",
       "38            2             100         2025    binary    auc         2333   \n",
       "39            2             100         2380    binary    auc         2333   \n",
       "40            2             100         1687    binary    auc         2333   \n",
       "41            2             100         2228    binary    auc         2333   \n",
       "42            2             100         2043    binary    auc         2333   \n",
       "43            2             100         1831    binary    auc         2333   \n",
       "44            2             100         2191    binary    auc         2333   \n",
       "45            2             100         2185    binary    auc         2333   \n",
       "46            2             100         2584    binary    auc         2333   \n",
       "47            2             100         2626    binary    auc         2333   \n",
       "48            2             100         2068    binary    auc         2333   \n",
       "49            2             100         2600    binary    auc         2333   \n",
       "50            2             100         2227    binary    auc         2333   \n",
       "51            2             100         1785    binary    auc         2333   \n",
       "52            2             100         2375    binary    auc         2333   \n",
       "53            2             100         2621    binary    auc         2333   \n",
       "54            2             100         1606    binary    auc         2333   \n",
       "55            2             100         1855    binary    auc         2333   \n",
       "56            2             100         4133    binary    auc         2333   \n",
       "57            2             100         2237    binary    auc         2333   \n",
       "58            2             100         2223    binary    auc         2333   \n",
       "59            2             100         1694    binary    auc         2333   \n",
       "60            2             100         2250    binary    auc         2333   \n",
       "61            2             100         1826    binary    auc         2333   \n",
       "62            2             100         1920    binary    auc         2333   \n",
       "63            2             100         2418    binary    auc         2333   \n",
       "64            2             100         1608    binary    auc         2333   \n",
       "65            2             100         1780    binary    auc         2333   \n",
       "66            2             100         2130    binary    auc         2333   \n",
       "67            2             100         1608    binary    auc         2333   \n",
       "68            2             100         2014    binary    auc         2333   \n",
       "69            2             100         3510    binary    auc         2333   \n",
       "70            2             100         3697    binary    auc         2333   \n",
       "71            2             100         1771    binary    auc         2333   \n",
       "72            2             100         1838    binary    auc         2333   \n",
       "73            2             100         2482    binary    auc         2333   \n",
       "74            2             100         2409    binary    auc         2333   \n",
       "75            2             100         2065    binary    auc         2333   \n",
       "76            2             100         2626    binary    auc         2333   \n",
       "77            2             100         2028    binary    auc         2333   \n",
       "78            2             100         1894    binary    auc         2333   \n",
       "79            2             100         1624    binary    auc         2333   \n",
       "80            2             100         2221    binary    auc         2333   \n",
       "81            2             100         1967    binary    auc         2333   \n",
       "82            2             100         4067    binary    auc         2333   \n",
       "83            2             100         1462    binary    auc         2333   \n",
       "84            2             100         1986    binary    auc         2333   \n",
       "85            2             100         2579    binary    auc         2333   \n",
       "86            2             100         2148    binary    auc         2333   \n",
       "87            2             100         2357    binary    auc         2333   \n",
       "88            2             100         2507    binary    auc         2333   \n",
       "89            2             100         4734    binary    auc         2333   \n",
       "90            2             100         2016    binary    auc         2333   \n",
       "91            2             100         1663    binary    auc         2333   \n",
       "92            2             100         2736    binary    auc         2333   \n",
       "93            2             100         1666    binary    auc         2333   \n",
       "94            2             100         1849    binary    auc         2333   \n",
       "95            2             100         1713    binary    auc         2333   \n",
       "96            2             100         3127    binary    auc         2333   \n",
       "97            2             100         5232    binary    auc         2333   \n",
       "98            2             100         1951    binary    auc         2333   \n",
       "99            2             100         2220    binary    auc         2333   \n",
       "\n",
       "   max_depth scale_pos_weight  iteration     score          valid_scores  \n",
       "0         15                1         73  0.507089   [0.677042755384619]  \n",
       "1         15                1         71  0.507080  [0.6768204493478739]  \n",
       "2         15                1         64  0.507080  [0.6768030742478867]  \n",
       "3         15                1         66  0.507079  [0.6767994268703607]  \n",
       "4         15                1         78  0.507078  [0.6767729035630919]  \n",
       "5         15                1         24  0.507078  [0.6767535532512398]  \n",
       "6         15                1         61  0.507075  [0.6766967740274316]  \n",
       "7         15                1         60  0.507074  [0.6766657442607642]  \n",
       "8         15                1         98  0.507073  [0.6766341341065009]  \n",
       "9         15                1         94  0.507070   [0.676570176475737]  \n",
       "10        15                1         53  0.507070  [0.6765674734118287]  \n",
       "11        15                1         69  0.507070  [0.6765605574645317]  \n",
       "12        15                1         74  0.507068  [0.6765137138269812]  \n",
       "13        15                1         92  0.507068  [0.6765061336132282]  \n",
       "14        15                1         77  0.507066  [0.6764748955022957]  \n",
       "15        15                1         12  0.507066  [0.6764736346136258]  \n",
       "16        15                1         99  0.507066  [0.6764728404702253]  \n",
       "17        15                1         68  0.507063  [0.6763938834052513]  \n",
       "18        15                1        100  0.507062  [0.6763703810898282]  \n",
       "19        15                1         39  0.507062  [0.6763596188909339]  \n",
       "20        15                1         51  0.507062  [0.6763549771430513]  \n",
       "21        15                1         10  0.507061    [0.67634347491615]  \n",
       "22        15                1         31  0.507061  [0.6763330008817264]  \n",
       "23        15                1         59  0.507060  [0.6763108744501846]  \n",
       "24        15                1         21  0.507059  [0.6763012256755128]  \n",
       "25        15                1         81  0.507059  [0.6762925509779251]  \n",
       "26        15                1         91  0.507059  [0.6762832607177357]  \n",
       "27        15                1         40  0.507059  [0.6762793941728658]  \n",
       "28        15                1         83  0.507058  [0.6762690297221142]  \n",
       "29        15                1         57  0.507058  [0.6762583771068919]  \n",
       "30        15                1         70  0.507057  [0.6762388157450047]  \n",
       "31        15                1          8  0.507057  [0.6762374953294018]  \n",
       "32        15                1          1  0.507057  [0.6762289505087588]  \n",
       "33        15                1          2  0.507056  [0.6762123357300509]  \n",
       "34        15                1         32  0.507056  [0.6762109003192367]  \n",
       "35        15                1         58  0.507056  [0.6762062775117419]  \n",
       "36        15                1         63  0.507056  [0.6762037909094077]  \n",
       "37        15                1          4  0.507055  [0.6761843567186955]  \n",
       "38        15                1         29  0.507054   [0.676159201177999]  \n",
       "39        15                1         25  0.507053  [0.6761391852468059]  \n",
       "40        15                1          7  0.507052  [0.6761251111858259]  \n",
       "41        15                1         37  0.507051  [0.6760993630815699]  \n",
       "42        15                1         95  0.507051  [0.6760991114449899]  \n",
       "43        15                1         84  0.507051  [0.6760862549803648]  \n",
       "44        15                1         65  0.507050  [0.6760679274494509]  \n",
       "45        15                1         18  0.507050  [0.6760655328432857]  \n",
       "46        15                1          6  0.507050  [0.6760652325028516]  \n",
       "47        15                1         55  0.507050  [0.6760612671973885]  \n",
       "48        15                1         80  0.507049  [0.6760437662791111]  \n",
       "49        15                1         56  0.507048  [0.6760022354203233]  \n",
       "50        15                1         82  0.507047  [0.6759908373655548]  \n",
       "51        15                1         23  0.507047  [0.6759820828477615]  \n",
       "52        15                1         44  0.507046  [0.6759699095899802]  \n",
       "53        15                1         76  0.507046   [0.675954095719097]  \n",
       "54        15                1         97  0.507045  [0.6759480456180971]  \n",
       "55        15                1         22  0.507045  [0.6759387945915679]  \n",
       "56        15                1         88  0.507043  [0.6758797817548906]  \n",
       "57        15                1         50  0.507042  [0.6758577270262451]  \n",
       "58        15                1         30  0.507041  [0.6758463600878278]  \n",
       "59        15                1         86  0.507041  [0.6758299428303066]  \n",
       "60        15                1         89  0.507040  [0.6758264523874219]  \n",
       "61        15                1         52  0.507040  [0.6758246909313615]  \n",
       "62        15                1         85  0.507040  [0.6758194620314588]  \n",
       "63        15                1         93  0.507040  [0.6758132982881323]  \n",
       "64        15                1         49  0.507039    [0.67579226769331]  \n",
       "65        15                1         34  0.507039  [0.6757776849476304]  \n",
       "66        15                1          9  0.507038  [0.6757611148141223]  \n",
       "67        15                1         17  0.507038  [0.6757571779192407]  \n",
       "68        15                1         20  0.507037  [0.6757320656708592]  \n",
       "69        15                1         46  0.507037  [0.6757283993529455]  \n",
       "70        15                1         54  0.507036  [0.6757052163183443]  \n",
       "71        15                1         42  0.507035  [0.6756947517541146]  \n",
       "72        15                1         13  0.507035  [0.6756938777905086]  \n",
       "73        15                1         47  0.507035  [0.6756911584919822]  \n",
       "74        15                1         26  0.507035  [0.6756882998463174]  \n",
       "75        15                1         72  0.507035  [0.6756870213701446]  \n",
       "76        15                1         27  0.507033  [0.6756454323373088]  \n",
       "77        15                1         35  0.507033  [0.6756384744505818]  \n",
       "78        15                1         41  0.507033  [0.6756276594891788]  \n",
       "79        15                1         67  0.507031  [0.6755842413560407]  \n",
       "80        15                1         36  0.507029  [0.6755432611213824]  \n",
       "81        15                1         43  0.507028  [0.6755260646021938]  \n",
       "82        15                1         48  0.507028  [0.6755177240671614]  \n",
       "83        15                1          5  0.507028  [0.6755150818830707]  \n",
       "84        15                1         15  0.507028  [0.6755030872060882]  \n",
       "85        15                1         45  0.507023  [0.6753942868544507]  \n",
       "86        15                1         14  0.507022  [0.6753556579336426]  \n",
       "87        15                1         87  0.507019    [0.67529937792434]  \n",
       "88        15                1         33  0.507018  [0.6752548734246762]  \n",
       "89        15                1          3  0.507018  [0.6752529482695503]  \n",
       "90        15                1         75  0.507017  [0.6752444616229553]  \n",
       "91        15                1         38  0.507016  [0.6752090444507549]  \n",
       "92        15                1         79  0.507015    [0.67519038952171]  \n",
       "93        15                1         90  0.507010  [0.6750586320672394]  \n",
       "94        15                1         19  0.507010  [0.6750580002700196]  \n",
       "95        15                1         62  0.507008  [0.6750179102335854]  \n",
       "96        15                1         96  0.507005  [0.6749510303715692]  \n",
       "97        15                1         16  0.507004  [0.6749228105467124]  \n",
       "98        15                1         28  0.506976  [0.6742160405077748]  \n",
       "99        15                1         11  0.506961  [0.6738403470937532]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_results = evaluate(results, 'Bayesian', train_df,target)\n",
    "bayes_results.to_csv('bayes_elo_cls_tabular.csv')\n",
    "bayes_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
